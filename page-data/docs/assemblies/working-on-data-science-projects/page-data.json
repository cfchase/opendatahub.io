{"componentChunkName":"component---src-templates-docs-page-tsx","path":"/docs/assemblies/working-on-data-science-projects/","result":{"data":{"allFile":{"edges":[{"node":{"childAsciidoc":{"fields":{"slug":"/docs/README/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/getting-started-with-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"overview-for-getting-started_get-started"},{"parentId":"overview-for-getting-started_get-started","name":"Data science workflow","level":2,"index":0,"id":"_data_science_workflow"},{"parentId":"overview-for-getting-started_get-started","name":"About this guide","level":2,"index":1,"id":"_about_this_guide"},{"parentId":null,"name":"Logging in to Open Data Hub","level":1,"index":1,"id":"logging-in_get-started"},{"parentId":null,"name":"Creating a data science project","level":1,"index":2,"id":"creating-a-data-science-project_get-started"},{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":3,"id":"creating-a-workbench-select-ide_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_get-started"},{"parentId":null,"name":"Next steps","level":1,"index":4,"id":"next-steps_get-started"},{"parentId":"next-steps_get-started","name":"Additional resources","level":2,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/installing-open-data-hub/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_installv2"},{"parentId":null,"name":"Installing Open Data Hub version 1","level":1,"index":1,"id":"installing-odh-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Installing the Open Data Hub Operator version 1","level":2,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Creating a new project for your Open Data Hub instance","level":2,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Adding an Open Data Hub instance","level":2,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Accessing the Open Data Hub dashboard","level":2,"index":3,"id":"accessing-the-odh-dashboard_installv1"},{"parentId":null,"name":"Configuring the Open Data Hub Operator logger","level":0,"index":2,"id":"configuring-the-odh-operator-logger_operator-log"},{"parentId":"configuring-the-odh-operator-logger_operator-log","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_operator-log"},{"parentId":"configuring-the-operator-logger_operator-log","name":"Viewing the Open Data Hub Operator log","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_log"},{"parentId":"configuring-the-odh-operator-logger_operator-log","name":"Working with certificates","level":1,"index":1,"id":"working-with-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Understanding certificates in Open Data Hub","level":2,"index":0,"id":"understanding-certificates_certs"},{"parentId":"understanding-certificates_certs","name":"How CA bundles are injected","level":3,"index":0,"id":"_how_ca_bundles_are_injected"},{"parentId":"understanding-certificates_certs","name":"How the ConfigMap is managed","level":3,"index":1,"id":"_how_the_configmap_is_managed"},{"parentId":"working-with-certificates_certs","name":"Adding a CA bundle","level":2,"index":1,"id":"adding-a-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Removing a CA bundle","level":2,"index":2,"id":"removing-a-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Removing a CA bundle from a namespace","level":2,"index":3,"id":"removing-a-ca-bundle-from-a-namespace_certs"},{"parentId":"working-with-certificates_certs","name":"Managing certificates","level":2,"index":4,"id":"managing-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Using self-signed certificates with Open Data Hub components","level":2,"index":5,"id":"_using_self_signed_certificates_with_open_data_hub_components"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Using certificates with data science pipelines","level":3,"index":0,"id":"using-certificates-with-data-science-pipelines_certs"},{"parentId":"using-certificates-with-data-science-pipelines_certs","name":"Providing a CA bundle only for data science pipelines","level":4,"index":0,"id":"_providing_a_ca_bundle_only_for_data_science_pipelines"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Using certificates with workbenches","level":3,"index":1,"id":"using-certificates-with-workbenches_certs"},{"parentId":"using-certificates-with-workbenches_certs","name":"Creating data science pipelines with Elyra and self-signed certificates","level":4,"index":0,"id":"_creating_data_science_pipelines_with_elyra_and_self_signed_certificates"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-resources/"},"sections":[{"parentId":null,"name":"Customizing the dashboard","level":1,"index":0,"id":"customizing-the-dashboard"},{"parentId":"customizing-the-dashboard","name":"Editing the dashboard configuration file","level":2,"index":0,"id":"editing-the-dashboard-configuration-file_dashboard"},{"parentId":"customizing-the-dashboard","name":"Dashboard configuration options","level":2,"index":1,"id":"ref-dashboard-configuration-options_dashboard"},{"parentId":null,"name":"Managing applications that show in the dashboard","level":1,"index":1,"id":"managing-applications-that-show-in-the-dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Adding an application to the dashboard","level":2,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Preventing users from adding applications to the dashboard","level":2,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Disabling applications connected to Open Data Hub","level":2,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Showing or hiding information about enabled applications","level":2,"index":3,"id":"showing-hiding-information-about-enabled-applications_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Hiding the default Jupyter application","level":2,"index":4,"id":"hiding-the-default-jupyter-application_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Troubleshooting common problems in Jupyter for administrators","level":2,"index":5,"id":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":3,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"A user&#8217;s notebook server does not start","level":3,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":3,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"},{"parentId":null,"name":"Managing cluster resources","level":1,"index":2,"id":"managing-cluster-resources"},{"parentId":"managing-cluster-resources","name":"Configuring the default PVC size for your cluster","level":2,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-resources","name":"Restoring the default PVC size for your cluster","level":2,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-resources","name":"Overview of accelerators","level":2,"index":2,"id":"overview-of-accelerators_managing-resources"},{"parentId":"overview-of-accelerators_managing-resources","name":"Enabling GPU support in Open Data Hub","level":3,"index":0,"id":"enabling-gpu-support_managing-resources"},{"parentId":"overview-of-accelerators_managing-resources","name":"Enabling Habana Gaudi devices","level":3,"index":1,"id":"enabling-habana-gaudi-devices_managing-resources"},{"parentId":"managing-cluster-resources","name":"Allocating additional resources to Open Data Hub users","level":2,"index":3,"id":"allocating-additional-resources-to-data-science-users_managing-resources"},{"parentId":null,"name":"Managing Jupyter notebook servers","level":1,"index":3,"id":"managing-notebook-servers"},{"parentId":"managing-notebook-servers","name":"Accessing the Jupyter administration interface","level":2,"index":0,"id":"accessing-the-jupyter-administration-interface_managing-resources"},{"parentId":"managing-notebook-servers","name":"Starting notebook servers owned by other users","level":2,"index":1,"id":"starting-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Accessing notebook servers owned by other users","level":2,"index":2,"id":"accessing-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Stopping notebook servers owned by other users","level":2,"index":3,"id":"stopping-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Stopping idle notebooks","level":2,"index":4,"id":"stopping-idle-notebooks_managing-resources"},{"parentId":"managing-notebook-servers","name":"Adding notebook pod tolerations","level":2,"index":5,"id":"adding-notebook-pod-tolerations_managing-resources"},{"parentId":"managing-notebook-servers","name":"Configuring a custom notebook image","level":2,"index":6,"id":"configuring-a-custom-notebook-image_managing-resources"},{"parentId":null,"name":"Backing up storage data","level":1,"index":4,"id":"backing-up-storage-data_managing-resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-users/"},"sections":[{"parentId":null,"name":"Adding users","level":1,"index":0,"id":"adding-users"},{"parentId":"adding-users","name":"Overview of user types and permissions","level":2,"index":0,"id":"overview-of-user-types-and-permissions_managing-users"},{"parentId":"adding-users","name":"Defining Open Data Hub administrator and user groups","level":2,"index":1,"id":"defining-data-science-admin-and-user-groups_managing-users"},{"parentId":"adding-users","name":"Adding users to specialized Open Data Hub user groups","level":2,"index":2,"id":"adding-users-to-specialized-data-science-user-groups_managing-users"},{"parentId":"adding-users","name":"Viewing Open Data Hub users","level":2,"index":3,"id":"viewing-data-science-users_managing-users"},{"parentId":null,"name":"Deleting users and their resources","level":1,"index":1,"id":"deleting-users"},{"parentId":"deleting-users","name":"About deleting users and their resources","level":2,"index":0,"id":"about-deleting-users-and-resources_managing-users"},{"parentId":"deleting-users","name":"Backing up storage data","level":2,"index":1,"id":"backing-up-storage-data_managing-users"},{"parentId":"deleting-users","name":"Stopping notebook servers owned by other users","level":2,"index":2,"id":"stopping-notebook-servers-owned-by-other-users_managing-users"},{"parentId":"deleting-users","name":"Revoking user access to Jupyter","level":2,"index":3,"id":"revoking-user-access-to-jupyter_managing-users"},{"parentId":"deleting-users","name":"Cleaning up after deleting users","level":2,"index":4,"id":"cleaning-up-after-deleting-users_managing-users"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-data-science-models/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service for a data science project","level":1,"index":0,"id":"enabling-trustyai-service_monitor"},{"parentId":"enabling-trustyai-service_monitor","name":"Enabling the TrustyAI Service by using the dashboard","level":2,"index":0,"id":"enabling-trustyai-service-using-dashboard_monitor"},{"parentId":"enabling-trustyai-service_monitor","name":"Enabling the TrustyAI Service by using the CLI","level":2,"index":1,"id":"enabling-trustyai-service-using-cli_monitor"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":1,"id":"authenticating-trustyai-service_monitor"},{"parentId":null,"name":"Sending training data to a model","level":1,"index":2,"id":"sending-training-data-to-a-model_monitor"},{"parentId":null,"name":"Configuring bias metrics for a model","level":1,"index":3,"id":"configuring-bias-metrics-for-a-model_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Duplicating a bias metric","level":2,"index":1,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Deleting a bias metric","level":2,"index":2,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Viewing bias metrics for a model","level":1,"index":4,"id":"viewing-bias-metrics_monitor"},{"parentId":null,"name":"Supported bias metrics","level":1,"index":5,"id":"supported-bias-metrics_monitor"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/serving-models/"},"sections":[{"parentId":null,"name":"About model serving","level":1,"index":0,"id":"about-model-serving_about-model-serving"},{"parentId":null,"name":"Serving small and medium-sized models","level":1,"index":1,"id":"serving-small-and-medium-sized-models_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring model servers","level":2,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":3,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":3,"index":2,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":3,"index":3,"id":"deleting-a-model-server_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Working with deployed models","level":2,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":3,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":3,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":3,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":3,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring monitoring for the multi-model serving platform","level":2,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":2,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Monitoring model performance","level":2,"index":4,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for all models on a model server","level":3,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance","name":"Viewing HTTP request metrics for a deployed model","level":3,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"},{"parentId":null,"name":"Serving large models","level":1,"index":2,"id":"serving-large-models_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"About the single-model serving platform","level":2,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Installing KServe","level":2,"index":1,"id":"installing-kserve_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Deploying models by using the single-model serving platform","level":2,"index":2,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":3,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":3,"index":2,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":3,"index":3,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Configuring monitoring for the single-model serving platform","level":2,"index":3,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Viewing model-serving runtime metrics for the single-model serving platform","level":2,"index":4,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Performance tuning on the single-model serving platform","level":2,"index":5,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":3,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/upgrading-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview of upgrading Open Data Hub","level":1,"index":0,"id":"overview-of-upgrading-odh_upgrade"},{"parentId":null,"name":"Requirements for upgrading Open Data Hub","level":1,"index":1,"id":"requirements-for-upgrading-odh_upgrade"},{"parentId":null,"name":"Upgrading Open Data Hub version 1 to version 2","level":1,"index":2,"id":"upgrading-odh-v1-to-v2_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Upgrading the Open Data Hub Operator version 1","level":2,"index":0,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_upgradev1"},{"parentId":null,"name":"Upgrading Open Data Hub version 2.0 to version 2.2","level":1,"index":3,"id":"upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Installing Open Data Hub version 2","level":2,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":3,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":3,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":3,"index":2,"id":"accessing-the-odh-dashboard_installv2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Adding a CA bundle after upgrading","level":2,"index":1,"id":"adding-a-ca-bundle-after-upgrading_upgradev2"},{"parentId":null,"name":"Adding a CA bundle after upgrading","level":1,"index":4,"id":"adding-a-ca-bundle-after-upgrading_upgradev2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Working on data science projects","level":1,"index":0,"id":"working-on-data-science-projects_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using data science projects","level":2,"index":0,"id":"_using_data_science_projects"},{"parentId":"_using_data_science_projects","name":"Creating a data science project","level":3,"index":0,"id":"creating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Updating a data science project","level":3,"index":1,"id":"updating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Deleting a data science project","level":3,"index":2,"id":"deleting-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using project workbenches","level":2,"index":1,"id":"_using_project_workbenches"},{"parentId":"_using_project_workbenches","name":"Creating a workbench and selecting an IDE","level":3,"index":0,"id":"creating-a-workbench-select-ide_nb-server"},{"parentId":"creating-a-workbench-select-ide_nb-server","name":"About workbench images","level":4,"index":0,"id":"about-workbench-images_nb-server"},{"parentId":"creating-a-workbench-select-ide_nb-server","name":"Creating a workbench","level":4,"index":1,"id":"creating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Starting a workbench","level":3,"index":1,"id":"starting-a-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Updating a project workbench","level":3,"index":2,"id":"updating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Deleting a workbench from a data science project","level":3,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using data connections","level":2,"index":2,"id":"_using_data_connections"},{"parentId":"_using_data_connections","name":"Adding a data connection to your data science project","level":3,"index":0,"id":"adding-a-data-connection-to-your-data-science-project_nb-server"},{"parentId":"_using_data_connections","name":"Deleting a data connection","level":3,"index":1,"id":"deleting-a-data-connection_nb-server"},{"parentId":"_using_data_connections","name":"Updating a connected data source","level":3,"index":2,"id":"updating-a-connected-data-source_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Configuring cluster storage","level":2,"index":3,"id":"_configuring_cluster_storage"},{"parentId":"_configuring_cluster_storage","name":"Adding cluster storage to your data science project","level":3,"index":0,"id":"adding-cluster-storage-to-your-data-science-project_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Updating cluster storage","level":3,"index":1,"id":"updating-cluster-storage_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Deleting cluster storage from a data science project","level":3,"index":2,"id":"deleting-cluster-storage-from-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Configuring access to data science projects","level":2,"index":4,"id":"_configuring_access_to_data_science_projects"},{"parentId":"_configuring_access_to_data_science_projects","name":"Configuring access to data science projects","level":3,"index":0,"id":"configuring-access-to-data-science-projects_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Sharing access to a data science project","level":3,"index":1,"id":"sharing-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Updating access to a data science project","level":3,"index":2,"id":"updating-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Removing access to a data science project","level":3,"index":3,"id":"removing-access-to-a-data-science-project_nb-server"},{"parentId":null,"name":"Working in your data science IDE","level":1,"index":1,"id":"working-in-your-data-science-ide"},{"parentId":"working-in-your-data-science-ide","name":"Accessing your workbench IDE","level":2,"index":0,"id":"accessing-your-workbench-ide_ide"},{"parentId":"working-in-your-data-science-ide","name":"Working in JupyterLab","level":2,"index":1,"id":"_working_in_jupyterlab"},{"parentId":"_working_in_jupyterlab","name":"Creating and importing notebooks","level":3,"index":0,"id":"_creating_and_importing_notebooks"},{"parentId":"_creating_and_importing_notebooks","name":"Creating a new notebook","level":4,"index":0,"id":"creating-a-new-notebook_ide"},{"parentId":"_creating_and_importing_notebooks","name":"Uploading an existing notebook file from local storage","level":4,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_ide"},{"parentId":"_working_in_jupyterlab","name":"Collaborating on notebooks by using Git","level":3,"index":1,"id":"_collaborating_on_notebooks_by_using_git"},{"parentId":"_working_in_jupyterlab","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":2,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide"},{"parentId":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide","name":"Uploading an existing notebook file from a Git repository by using the command line interface","level":4,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_ide"},{"parentId":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide","name":"Updating your project with changes from a remote Git repository","level":4,"index":1,"id":"updating-your-project-with-changes-from-a-remote-git-repository_ide"},{"parentId":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide","name":"Pushing project changes to a Git repository","level":4,"index":2,"id":"pushing-project-changes-to-a-git-repository_ide"},{"parentId":"_working_in_jupyterlab","name":"Managing Python packages","level":3,"index":3,"id":"_managing_python_packages"},{"parentId":"_managing_python_packages","name":"Viewing Python packages installed on your notebook server","level":4,"index":0,"id":"viewing-python-packages-installed-on-your-notebook-server_ide"},{"parentId":"_managing_python_packages","name":"Installing Python packages on your notebook server","level":4,"index":1,"id":"installing-python-packages-on-your-notebook-server_ide"},{"parentId":"_working_in_jupyterlab","name":"Troubleshooting common problems in Jupyter for users","level":3,"index":4,"id":"troubleshooting-common-problems-in-jupyter-for-users_ide"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":4,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"My notebook server does not start","level":4,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":4,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"},{"parentId":"working-in-your-data-science-ide","name":"Working in code-server","level":2,"index":2,"id":"working-in-code-server_ide"},{"parentId":"working-in-code-server_ide","name":"Installing extensions with code-server","level":3,"index":0,"id":"_installing_extensions_with_code_server"},{"parentId":null,"name":"Working with data science pipelines","level":1,"index":2,"id":"working-with-data-science-pipelines_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Enabling Data Science Pipelines 2.0","level":2,"index":0,"id":"enabling-data-science-pipelines-2_ds-pipelines"},{"parentId":"enabling-data-science-pipelines-2_ds-pipelines","name":"Installing Open Data Hub with DSP 2.0","level":3,"index":0,"id":"_installing_open_data_hub_with_dsp_2_0"},{"parentId":"enabling-data-science-pipelines-2_ds-pipelines","name":"Upgrading to DSP 2.0","level":3,"index":1,"id":"_upgrading_to_dsp_2_0"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Managing data science pipelines","level":2,"index":1,"id":"_managing_data_science_pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Configuring a pipeline server","level":3,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Defining a pipeline","level":3,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Importing a data science pipeline","level":3,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Downloading a data science pipeline version","level":3,"index":3,"id":"downloading-a-data-science-pipeline-version_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a data science pipeline","level":3,"index":4,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a pipeline server","level":3,"index":5,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing the details of a pipeline server","level":3,"index":6,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing existing pipelines","level":3,"index":7,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Managing pipeline runs","level":2,"index":2,"id":"_managing_pipeline_runs"},{"parentId":"_managing_pipeline_runs","name":"Overview of pipeline runs","level":3,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Storing data with data science pipelines","level":3,"index":1,"id":"storing-data-with-data-science-pipelines_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing active pipeline runs","level":3,"index":2,"id":"viewing-active-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Executing a pipeline run","level":3,"index":3,"id":"executing-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Stopping an active pipeline run","level":3,"index":4,"id":"stopping-an-active-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating an active pipeline run","level":3,"index":5,"id":"duplicating-an-active-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing scheduled pipeline runs","level":3,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run using a cron job","level":3,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run","level":3,"index":8,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating a scheduled pipeline run","level":3,"index":9,"id":"duplicating-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a scheduled pipeline run","level":3,"index":10,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing the details of a pipeline run","level":3,"index":11,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing archived pipeline runs","level":3,"index":12,"id":"viewing-archived-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Archiving a pipeline run","level":3,"index":13,"id":"archiving-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Restoring an archived pipeline run","level":3,"index":14,"id":"restoring-an-archived-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting an archived pipeline run","level":3,"index":15,"id":"deleting-an-archived-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating an archived pipeline run","level":3,"index":16,"id":"duplicating-an-archived-pipeline-run_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Working with pipeline logs","level":2,"index":3,"id":"_working_with_pipeline_logs"},{"parentId":"_working_with_pipeline_logs","name":"About pipeline logs","level":3,"index":0,"id":"about-pipeline-logs_ds-pipelines"},{"parentId":"_working_with_pipeline_logs","name":"Viewing pipeline step logs","level":3,"index":1,"id":"viewing-pipeline-step-logs_ds-pipelines"},{"parentId":"_working_with_pipeline_logs","name":"Downloading pipeline step logs","level":3,"index":2,"id":"downloading-pipeline-step-logs_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Working with pipelines in JupyterLab","level":2,"index":4,"id":"_working_with_pipelines_in_jupyterlab"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Overview of pipelines in JupyterLab","level":3,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Accessing the pipeline editor","level":3,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Creating a runtime configuration","level":3,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Updating a runtime configuration","level":3,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Deleting a runtime configuration","level":3,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Duplicating a runtime configuration","level":3,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Running a pipeline in JupyterLab","level":3,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Exporting a pipeline in JupyterLab","level":3,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Additional resources","level":2,"index":5,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-accelerators/"},"sections":[{"parentId":null,"name":"Overview of accelerators","level":1,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":null,"name":"Working with accelerator profiles","level":1,"index":1,"id":"working-with-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Creating an accelerator profile","level":2,"index":0,"id":"creating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Updating an accelerator profile","level":2,"index":1,"id":"updating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Deleting an accelerator profile","level":2,"index":2,"id":"deleting-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Viewing accelerator profiles","level":2,"index":3,"id":"viewing-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for notebook images","level":2,"index":4,"id":"configuring-a-recommended-accelerator-for-notebook-images_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":2,"index":5,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":null,"name":"Habana Gaudi integration","level":1,"index":2,"id":"habana-gaudi-integration_accelerators"},{"parentId":"habana-gaudi-integration_accelerators","name":"Enabling Habana Gaudi devices","level":2,"index":0,"id":"enabling-habana-gaudi-devices_accelerators"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-connected-applications/"},"sections":[{"parentId":null,"name":"Viewing applications that are connected to Open Data Hub","level":1,"index":0,"id":"viewing-connected-applications_connected-apps"},{"parentId":null,"name":"Enabling applications that are connected to Open Data Hub","level":1,"index":1,"id":"enabling-applications-connected_connected-apps"},{"parentId":null,"name":"Removing disabled applications from the dashboard","level":1,"index":2,"id":"removing-disabled-applications_connected-apps"},{"parentId":null,"name":"Using the Jupyter application","level":1,"index":3,"id":"_using_the_jupyter_application"},{"parentId":"_using_the_jupyter_application","name":"Starting a Jupyter notebook server","level":2,"index":0,"id":"starting-a-jupyter-notebook-server_connected-apps"},{"parentId":"_using_the_jupyter_application","name":"Creating and importing notebooks","level":2,"index":1,"id":"_creating_and_importing_notebooks"},{"parentId":"_creating_and_importing_notebooks","name":"Creating a new notebook","level":3,"index":0,"id":"creating-a-new-notebook_connected-apps"},{"parentId":"_creating_and_importing_notebooks","name":"Uploading an existing notebook file from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_connected-apps"},{"parentId":"_using_the_jupyter_application","name":"Collaborating on notebooks by using Git","level":2,"index":2,"id":"collaborating-on-notebooks-using-git_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Uploading an existing notebook file from a Git repository by using the command line interface","level":3,"index":1,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_git-collab"},{"parentId":"_using_the_jupyter_application","name":"Managing Python packages","level":2,"index":3,"id":"_managing_python_packages"},{"parentId":"_managing_python_packages","name":"Viewing Python packages installed on your notebook server","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-notebook-server_connected-apps"},{"parentId":"_managing_python_packages","name":"Installing Python packages on your notebook server","level":3,"index":1,"id":"installing-python-packages-on-your-notebook-server_connected-apps"},{"parentId":"_using_the_jupyter_application","name":"Updating notebook server settings by restarting your server","level":2,"index":4,"id":"updating-notebook-server-settings-by-restarting-your-server_connected-apps"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of distributed workloads","level":1,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Overview of Kueue resources","level":2,"index":0,"id":"overview-of-kueue-resources_distributed-workloads"},{"parentId":"overview-of-kueue-resources_distributed-workloads","name":"Resource flavour","level":3,"index":0,"id":"_resource_flavour"},{"parentId":"overview-of-kueue-resources_distributed-workloads","name":"Cluster queue","level":3,"index":1,"id":"_cluster_queue"},{"parentId":"overview-of-kueue-resources_distributed-workloads","name":"Local queue","level":3,"index":2,"id":"_local_queue"},{"parentId":null,"name":"Configuring distributed workloads","level":1,"index":1,"id":"configuring-distributed-workloads_distributed-workloads"},{"parentId":"configuring-distributed-workloads_distributed-workloads","name":"Configuring the distributed workloads components","level":2,"index":0,"id":"configuring-the-distributed-workloads-components_distributed-workloads"},{"parentId":"configuring-distributed-workloads_distributed-workloads","name":"Configuring quota management for distributed workloads","level":2,"index":1,"id":"configuring-quota-management-for-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Running distributed workloads","level":1,"index":2,"id":"running-distributed-workloads_distributed-workloads"},{"parentId":"running-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from notebooks","level":2,"index":0,"id":"running-distributed-data-science-workloads-from-notebooks_distributed-workloads"},{"parentId":"running-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from data science pipelines","level":2,"index":1,"id":"running-distributed-data-science-workloads-from-ds-pipelines_distributed-workloads"},{"parentId":null,"name":"Monitoring distributed workloads","level":1,"index":3,"id":"monitoring-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing project metrics for distributed workloads","level":2,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing the status of distributed workloads","level":2,"index":1,"id":"viewing-the-status-of-distributed-workloads_distributed-workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/_artifacts/document-attributes-global/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/adding-users/"},"sections":[{"parentId":null,"name":"Overview of user types and permissions","level":1,"index":0,"id":"overview-of-user-types-and-permissions_{context}"},{"parentId":null,"name":"Defining {productname-short} administrator and user groups","level":1,"index":1,"id":"defining-data-science-admin-and-user-groups_{context}"},{"parentId":null,"name":"Adding users to specialized {productname-short} user groups","level":1,"index":2,"id":"adding-users-to-specialized-data-science-user-groups_{context}"},{"parentId":null,"name":"Viewing {productname-short} users","level":1,"index":3,"id":"viewing-data-science-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-notebooks-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_git-collab"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using the command line interface","level":1,"index":1,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_git-collab"},{"parentId":null,"name":"Updating your project with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_git-collab"},{"parentId":null,"name":"Pushing project changes to a Git repository","level":1,"index":3,"id":"pushing-project-changes-to-a-git-repository_git-collab"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-bias-metrics-for-a-model/"},"sections":[{"parentId":null,"name":"Creating a bias metric","level":1,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":2,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":2,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Duplicating a bias metric","level":1,"index":1,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":null,"name":"Deleting a bias metric","level":1,"index":2,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":2,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":2,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-the-odh-operator-logger/"},"sections":[{"parentId":null,"name":"Configuring the {productname-short} Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_operator-log"},{"parentId":"configuring-the-operator-logger_operator-log","name":"Viewing the {productname-short} Operator log","level":3,"index":0,"id":"_viewing_the_productname_short_operator_log"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-and-importing-notebooks/"},"sections":[{"parentId":null,"name":"Creating a new notebook","level":1,"index":0,"id":"creating-a-new-notebook_notebooks"},{"parentId":"creating-a-new-notebook_notebooks","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":1,"index":2,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using the command line interface","level":1,"index":3,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_notebooks"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-the-dashboard/"},"sections":[{"parentId":null,"name":"Editing the dashboard configuration file","level":1,"index":0,"id":"editing-the-dashboard-configuration-file_dashboard"},{"parentId":null,"name":"Dashboard configuration options","level":1,"index":1,"id":"ref-dashboard-configuration-options_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deleting-users/"},"sections":[{"parentId":null,"name":"About deleting users and their resources","level":1,"index":0,"id":"about-deleting-users-and-resources_{context}"},{"parentId":null,"name":"Backing up storage data","level":1,"index":1,"id":"backing-up-storage-data_{context}"},{"parentId":null,"name":"Stopping notebook servers owned by other users","level":1,"index":2,"id":"stopping-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Revoking user access to Jupyter","level":1,"index":3,"id":"revoking-user-access-to-jupyter_{context}"},{"parentId":null,"name":"Cleaning up after deleting users","level":1,"index":4,"id":"cleaning-up-after-deleting-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v1/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 1","level":1,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":null,"name":"Creating a new project for your Open Data Hub instance","level":1,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":null,"name":"Adding an Open Data Hub instance","level":1,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v2/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 2","level":1,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":1,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":2,"id":"accessing-the-odh-dashboard_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-applications-that-show-in-the-dashboard/"},"sections":[{"parentId":null,"name":"Adding an application to the dashboard","level":1,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":null,"name":"Preventing users from adding applications to the dashboard","level":1,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":null,"name":"Disabling applications connected to {productname-short}","level":1,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":null,"name":"Showing or hiding information about enabled applications","level":1,"index":3,"id":"showing-hiding-information-about-enabled-applications_dashboard"},{"parentId":null,"name":"Hiding the default Jupyter application","level":1,"index":4,"id":"hiding-the-default-jupyter-application_dashboard"},{"parentId":null,"name":"Troubleshooting common problems in Jupyter for administrators","level":1,"index":5,"id":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":2,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"A user&#8217;s notebook server does not start","level":2,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_dashboard","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":2,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-cluster-resources/"},"sections":[{"parentId":null,"name":"Configuring the default PVC size for your cluster","level":1,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Restoring the default PVC size for your cluster","level":1,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Overview of accelerators","level":1,"index":2,"id":"overview-of-accelerators_{context}"},{"parentId":"overview-of-accelerators_{context}","name":"Enabling GPU support in {productname-short}","level":2,"index":0,"id":"enabling-gpu-support_{context}"},{"parentId":"overview-of-accelerators_{context}","name":"Enabling Habana Gaudi devices","level":2,"index":1,"id":"enabling-habana-gaudi-devices_{context}"},{"parentId":null,"name":"Allocating additional resources to {productname-short} users","level":1,"index":3,"id":"allocating-additional-resources-to-data-science-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-notebook-servers/"},"sections":[{"parentId":null,"name":"Accessing the Jupyter administration interface","level":1,"index":0,"id":"accessing-the-jupyter-administration-interface_{context}"},{"parentId":null,"name":"Starting notebook servers owned by other users","level":1,"index":1,"id":"starting-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Accessing notebook servers owned by other users","level":1,"index":2,"id":"accessing-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping notebook servers owned by other users","level":1,"index":3,"id":"stopping-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping idle notebooks","level":1,"index":4,"id":"stopping-idle-notebooks_{context}"},{"parentId":null,"name":"Adding notebook pod tolerations","level":1,"index":5,"id":"adding-notebook-pod-tolerations_{context}"},{"parentId":null,"name":"Configuring a custom notebook image","level":1,"index":6,"id":"configuring-a-custom-notebook-image_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-performance/"},"sections":[{"parentId":null,"name":"Viewing performance metrics for all models on a model server","level":1,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":null,"name":"Viewing HTTP request metrics for a deployed model","level":1,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-large-models/"},"sections":[{"parentId":null,"name":"About the single-model serving platform","level":1,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Installing KServe","level":1,"index":1,"id":"installing-kserve_serving-large-models"},{"parentId":null,"name":"Deploying models by using the single-model serving platform","level":1,"index":2,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":2,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":2,"index":2,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":2,"index":3,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":null,"name":"Configuring monitoring for the single-model serving platform","level":1,"index":3,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the single-model serving platform","level":1,"index":4,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Performance tuning on the single-model serving platform","level":1,"index":5,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":2,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-small-and-medium-sized-models/"},"sections":[{"parentId":null,"name":"Configuring model servers","level":1,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":2,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":2,"index":2,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":2,"index":3,"id":"deleting-a-model-server_model-serving"},{"parentId":null,"name":"Working with deployed models","level":1,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":2,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":2,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":2,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":2,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":null,"name":"Configuring monitoring for the multi-model serving platform","level":1,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":1,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":4,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for all models on a model server","level":2,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance","name":"Viewing HTTP request metrics for a deployed model","level":2,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v1-to-v2/"},"sections":[{"parentId":null,"name":"Upgrading the Open Data Hub Operator version 1","level":1,"index":0,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":1,"id":"installing-odh-components_upgradev1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":2,"id":"accessing-the-odh-dashboard_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v2/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_installv2"},{"parentId":null,"name":"Adding a CA bundle after upgrading","level":1,"index":1,"id":"adding-a-ca-bundle-after-upgrading_upgradev2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-in-your-data-science-ide/"},"sections":[{"parentId":null,"name":"Accessing your workbench IDE","level":1,"index":0,"id":"accessing-your-workbench-ide_ide"},{"parentId":null,"name":"Working in JupyterLab","level":1,"index":1,"id":"_working_in_jupyterlab"},{"parentId":"_working_in_jupyterlab","name":"Creating and importing notebooks","level":2,"index":0,"id":"_creating_and_importing_notebooks"},{"parentId":"_creating_and_importing_notebooks","name":"Creating a new notebook","level":3,"index":0,"id":"creating-a-new-notebook_ide"},{"parentId":"_creating_and_importing_notebooks","name":"Uploading an existing notebook file from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_ide"},{"parentId":"_working_in_jupyterlab","name":"Collaborating on notebooks by using Git","level":2,"index":1,"id":"_collaborating_on_notebooks_by_using_git"},{"parentId":"_collaborating_on_notebooks_by_using_git","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide"},{"parentId":"_collaborating_on_notebooks_by_using_git","name":"Uploading an existing notebook file from a Git repository by using the command line interface","level":3,"index":1,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_ide"},{"parentId":"_collaborating_on_notebooks_by_using_git","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_ide"},{"parentId":"_collaborating_on_notebooks_by_using_git","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_ide"},{"parentId":"_working_in_jupyterlab","name":"Managing Python packages","level":2,"index":2,"id":"_managing_python_packages"},{"parentId":"_managing_python_packages","name":"Viewing Python packages installed on your notebook server","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-notebook-server_ide"},{"parentId":"_managing_python_packages","name":"Installing Python packages on your notebook server","level":3,"index":1,"id":"installing-python-packages-on-your-notebook-server_ide"},{"parentId":"_working_in_jupyterlab","name":"Troubleshooting common problems in Jupyter for users","level":2,"index":3,"id":"troubleshooting-common-problems-in-jupyter-for-users_ide"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":3,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"My notebook server does not start","level":3,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_ide","name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":3,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"},{"parentId":null,"name":"Working in code-server","level":1,"index":2,"id":"working-in-code-server_ide"},{"parentId":"working-in-code-server_ide","name":"Installing extensions with code-server","level":2,"index":0,"id":"_installing_extensions_with_code_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Using data science projects","level":1,"index":0,"id":"_using_data_science_projects"},{"parentId":"_using_data_science_projects","name":"Creating a data science project","level":2,"index":0,"id":"creating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Updating a data science project","level":2,"index":1,"id":"updating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Deleting a data science project","level":2,"index":2,"id":"deleting-a-data-science-project_nb-server"},{"parentId":null,"name":"Using project workbenches","level":1,"index":1,"id":"_using_project_workbenches"},{"parentId":"_using_project_workbenches","name":"Creating a workbench and selecting an IDE","level":2,"index":0,"id":"creating-a-workbench-select-ide_nb-server"},{"parentId":"creating-a-workbench-select-ide_nb-server","name":"About workbench images","level":3,"index":0,"id":"about-workbench-images_nb-server"},{"parentId":"creating-a-workbench-select-ide_nb-server","name":"Creating a workbench","level":3,"index":1,"id":"creating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Starting a workbench","level":2,"index":1,"id":"starting-a-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Updating a project workbench","level":2,"index":2,"id":"updating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Deleting a workbench from a data science project","level":2,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_nb-server"},{"parentId":null,"name":"Using data connections","level":1,"index":2,"id":"_using_data_connections"},{"parentId":"_using_data_connections","name":"Adding a data connection to your data science project","level":2,"index":0,"id":"adding-a-data-connection-to-your-data-science-project_nb-server"},{"parentId":"_using_data_connections","name":"Deleting a data connection","level":2,"index":1,"id":"deleting-a-data-connection_nb-server"},{"parentId":"_using_data_connections","name":"Updating a connected data source","level":2,"index":2,"id":"updating-a-connected-data-source_nb-server"},{"parentId":null,"name":"Configuring cluster storage","level":1,"index":3,"id":"_configuring_cluster_storage"},{"parentId":"_configuring_cluster_storage","name":"Adding cluster storage to your data science project","level":2,"index":0,"id":"adding-cluster-storage-to-your-data-science-project_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Updating cluster storage","level":2,"index":1,"id":"updating-cluster-storage_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Deleting cluster storage from a data science project","level":2,"index":2,"id":"deleting-cluster-storage-from-a-data-science-project_nb-server"},{"parentId":null,"name":"Configuring access to data science projects","level":1,"index":4,"id":"_configuring_access_to_data_science_projects"},{"parentId":"_configuring_access_to_data_science_projects","name":"Configuring access to data science projects","level":2,"index":0,"id":"configuring-access-to-data-science-projects_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Sharing access to a data science project","level":2,"index":1,"id":"sharing-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Updating access to a data science project","level":2,"index":2,"id":"updating-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Removing access to a data science project","level":2,"index":3,"id":"removing-access-to-a-data-science-project_nb-server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-certificates/"},"sections":[{"parentId":null,"name":"Understanding certificates in {productname-short}","level":1,"index":0,"id":"understanding-certificates_certs"},{"parentId":"understanding-certificates_certs","name":"How CA bundles are injected","level":2,"index":0,"id":"_how_ca_bundles_are_injected"},{"parentId":"understanding-certificates_certs","name":"How the ConfigMap is managed","level":2,"index":1,"id":"_how_the_configmap_is_managed"},{"parentId":null,"name":"Adding a CA bundle","level":1,"index":1,"id":"adding-a-ca-bundle_certs"},{"parentId":null,"name":"Removing a CA bundle","level":1,"index":2,"id":"removing-a-ca-bundle_certs"},{"parentId":null,"name":"Removing a CA bundle from a namespace","level":1,"index":3,"id":"removing-a-ca-bundle-from-a-namespace_certs"},{"parentId":null,"name":"Managing certificates","level":1,"index":4,"id":"managing-certificates_certs"},{"parentId":null,"name":"Using self-signed certificates with {productname-short} components","level":1,"index":5,"id":"_using_self_signed_certificates_with_productname_short_components"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Using certificates with data science pipelines","level":2,"index":0,"id":"using-certificates-with-data-science-pipelines_certs"},{"parentId":"using-certificates-with-data-science-pipelines_certs","name":"Providing a CA bundle only for data science pipelines","level":3,"index":0,"id":"_providing_a_ca_bundle_only_for_data_science_pipelines"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Using certificates with workbenches","level":2,"index":1,"id":"using-certificates-with-workbenches_certs"},{"parentId":"using-certificates-with-workbenches_certs","name":"Creating data science pipelines with Elyra and self-signed certificates","level":3,"index":0,"id":"_creating_data_science_pipelines_with_elyra_and_self_signed_certificates"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Enabling Data Science Pipelines 2.0","level":1,"index":0,"id":"enabling-data-science-pipelines-2_ds-pipelines"},{"parentId":"enabling-data-science-pipelines-2_ds-pipelines","name":"Installing {productname-short} with DSP 2.0","level":2,"index":0,"id":"_installing_productname_short_with_dsp_2_0"},{"parentId":"enabling-data-science-pipelines-2_ds-pipelines","name":"Upgrading to DSP 2.0","level":2,"index":1,"id":"_upgrading_to_dsp_2_0"},{"parentId":null,"name":"Managing data science pipelines","level":1,"index":1,"id":"_managing_data_science_pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Configuring a pipeline server","level":2,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Defining a pipeline","level":2,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Importing a data science pipeline","level":2,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Downloading a data science pipeline version","level":2,"index":3,"id":"downloading-a-data-science-pipeline-version_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a data science pipeline","level":2,"index":4,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a pipeline server","level":2,"index":5,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing the details of a pipeline server","level":2,"index":6,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing existing pipelines","level":2,"index":7,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":null,"name":"Managing pipeline runs","level":1,"index":2,"id":"_managing_pipeline_runs"},{"parentId":"_managing_pipeline_runs","name":"Overview of pipeline runs","level":2,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Storing data with data science pipelines","level":2,"index":1,"id":"storing-data-with-data-science-pipelines_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing active pipeline runs","level":2,"index":2,"id":"viewing-active-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Executing a pipeline run","level":2,"index":3,"id":"executing-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Stopping an active pipeline run","level":2,"index":4,"id":"stopping-an-active-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating an active pipeline run","level":2,"index":5,"id":"duplicating-an-active-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing scheduled pipeline runs","level":2,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run using a cron job","level":2,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run","level":2,"index":8,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating a scheduled pipeline run","level":2,"index":9,"id":"duplicating-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a scheduled pipeline run","level":2,"index":10,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing the details of a pipeline run","level":2,"index":11,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing archived pipeline runs","level":2,"index":12,"id":"viewing-archived-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Archiving a pipeline run","level":2,"index":13,"id":"archiving-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Restoring an archived pipeline run","level":2,"index":14,"id":"restoring-an-archived-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting an archived pipeline run","level":2,"index":15,"id":"deleting-an-archived-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Duplicating an archived pipeline run","level":2,"index":16,"id":"duplicating-an-archived-pipeline-run_ds-pipelines"},{"parentId":null,"name":"Working with pipeline logs","level":1,"index":3,"id":"_working_with_pipeline_logs"},{"parentId":"_working_with_pipeline_logs","name":"About pipeline logs","level":2,"index":0,"id":"about-pipeline-logs_ds-pipelines"},{"parentId":"_working_with_pipeline_logs","name":"Viewing pipeline step logs","level":2,"index":1,"id":"viewing-pipeline-step-logs_ds-pipelines"},{"parentId":"_working_with_pipeline_logs","name":"Downloading pipeline step logs","level":2,"index":2,"id":"downloading-pipeline-step-logs_ds-pipelines"},{"parentId":null,"name":"Working with pipelines in JupyterLab","level":1,"index":4,"id":"_working_with_pipelines_in_jupyterlab"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Overview of pipelines in JupyterLab","level":2,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Accessing the pipeline editor","level":2,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Creating a runtime configuration","level":2,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Updating a runtime configuration","level":2,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Deleting a runtime configuration","level":2,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Duplicating a runtime configuration","level":2,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Running a pipeline in JupyterLab","level":2,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Exporting a pipeline in JupyterLab","level":2,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":null,"name":"Additional resources","level":1,"index":5,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-authorization-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-jupyter-administration-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-ca-bundle-after-upgrading/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-data-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-notebook-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-users-to-specialized-data-science-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-custom-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-notebook-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-access-to-data-science-projects/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator log","level":1,"index":0,"id":"_viewing_the_productname_short_operator_log"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-data-science-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-dashboard-configuration-file/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Installing {productname-short} with DSP 2.0","level":1,"index":0,"id":"_installing_productname_short_with_dsp_2_0"},{"parentId":null,"name":"Upgrading to DSP 2.0","level":1,"index":1,"id":"_upgrading_to_dsp_2_0"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-gpu-support-in-data-science/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-habana-gaudi-devices/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service by using the dashboard","level":1,"index":0,"id":"enabling-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Enabling the TrustyAI Service by using the CLI","level":1,"index":1,"id":"enabling-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/habana-gaudi-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/hiding-information-about-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/hiding-the-default-jupyter-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/monitoring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavour","level":1,"index":0,"id":"_resource_flavour"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-a-ca-bundle-from-a-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-a-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/revoking-user-access-to-jupyter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sending-training-data-to-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/showing-hiding-information-about-enabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-jupyter-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-idle-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/supported-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-jupyter-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s notebook server does not start","level":1,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-jupyter-for-users/"},"sections":[{"parentId":null,"name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":1,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":null,"name":"My notebook server does not start","level":1,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":null,"name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":1,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-certificates/"},"sections":[{"parentId":null,"name":"How CA bundles are injected","level":1,"index":0,"id":"_how_ca_bundles_are_injected"},{"parentId":null,"name":"How the ConfigMap is managed","level":1,"index":1,"id":"_how_the_configmap_is_managed"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-connected-data-source/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-notebook-server-settings-by-restarting-your-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-certificates-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Providing a CA bundle only for data science pipelines","level":1,"index":0,"id":"_providing_a_ca_bundle_only_for_data_science_pipelines"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-in-code-server/"},"sections":[{"parentId":null,"name":"Installing extensions with code-server","level":1,"index":0,"id":"_installing_extensions_with_code_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-authorization-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-jupyter-administration-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-ca-bundle-after-upgrading/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-data-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-notebook-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-users-to-specialized-data-science-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-custom-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-notebook-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-access-to-data-science-projects/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator log","level":1,"index":0,"id":"_viewing_the_productname_short_operator_log"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-data-science-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-dashboard-configuration-file/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Installing {productname-short} with DSP 2.0","level":1,"index":0,"id":"_installing_productname_short_with_dsp_2_0"},{"parentId":null,"name":"Upgrading to DSP 2.0","level":1,"index":1,"id":"_upgrading_to_dsp_2_0"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-gpu-support-in-data-science/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-habana-gaudi-devices/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service by using the dashboard","level":1,"index":0,"id":"enabling-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Enabling the TrustyAI Service by using the CLI","level":1,"index":1,"id":"enabling-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/habana-gaudi-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/hiding-information-about-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/hiding-the-default-jupyter-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/monitoring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavour","level":1,"index":0,"id":"_resource_flavour"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-a-ca-bundle-from-a-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-a-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/revoking-user-access-to-jupyter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sending-training-data-to-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/showing-hiding-information-about-enabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-jupyter-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-idle-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/supported-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-jupyter-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s notebook server does not start","level":1,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-jupyter-for-users/"},"sections":[{"parentId":null,"name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":1,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":null,"name":"My notebook server does not start","level":1,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":null,"name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":1,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-certificates/"},"sections":[{"parentId":null,"name":"How CA bundles are injected","level":1,"index":0,"id":"_how_ca_bundles_are_injected"},{"parentId":null,"name":"How the ConfigMap is managed","level":1,"index":1,"id":"_how_the_configmap_is_managed"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-connected-data-source/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-notebook-server-settings-by-restarting-your-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-certificates-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Providing a CA bundle only for data science pipelines","level":1,"index":0,"id":"_providing_a_ca_bundle_only_for_data_science_pipelines"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-certificates-with-workbenches/"},"sections":[{"parentId":null,"name":"Creating data science pipelines with Elyra and self-signed certificates","level":1,"index":0,"id":"_creating_data_science_pipelines_with_elyra_and_self_signed_certificates"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-in-code-server/"},"sections":[{"parentId":null,"name":"Installing extensions with code-server","level":1,"index":0,"id":"_installing_extensions_with_code_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-certificates-with-workbenches/"},"sections":[{"parentId":null,"name":"Creating data science pipelines with Elyra and self-signed certificates","level":1,"index":0,"id":"_creating_data_science_pipelines_with_elyra_and_self_signed_certificates"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-accelerator-profiles/"},"sections":null}}}]},"asciidoc":{"html":"<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a data scientist, you can organize your data science work into a single project. A data science project in {productname-short} can consist of the following components:</p>\n</div>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">Workbenches</dt>\n<dd>\n<p>Creating a workbench allows you to add a Jupyter notebook to your project.</p>\n</dd>\n<dt class=\"hdlist1\">Cluster storage</dt>\n<dd>\n<p>For data science projects that require data retention, you can add cluster storage to the project.</p>\n</dd>\n<dt class=\"hdlist1\">Data connections</dt>\n<dd>\n<p>Adding a data connection to your project allows you to connect data inputs to your workbenches.</p>\n</dd>\n<dt class=\"hdlist1\">Pipelines</dt>\n<dd>\n<p>Standardize and automate machine learning workflows to enable you to further enhance and deploy your data science models.</p>\n</dd>\n<dt class=\"hdlist1\">Models and model servers</dt>\n<dd>\n<p>Deploy a trained data science model to serve intelligent applications. Your model is deployed with an endpoint that allows applications to send requests to the model.</p>\n</dd>\n<dt class=\"hdlist1\">Bias metrics for models</dt>\n<dd>\n<p>Creating bias metrics allows you to monitor your machine learning models for bias.</p>\n</dd>\n</dl>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you create an OpenShift project outside of the {productname-short} user interface, the project is not shown on the <strong>Data Science Projects</strong> page. In addition, you cannot use features exclusive to {productname-short}, such as workbenches and model serving, with a standard OpenShift project.</p>\n</div>\n<div class=\"paragraph\">\n<p>To classify your OpenShift project as a data science project, and to make available features exclusive to {productname-short}, you must add the label <code>opendatahub.io/dashboard: 'true'</code> to the project namespace. After you add this label, your project is subsequently shown on the <strong>Data Science Projects</strong> page.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_data_science_projects\">Using data science projects</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"creating-a-data-science-project_nb-server\">Creating a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>To implement a data science workflow, you must create a project. In OpenShift, a project is a Kubernetes namespace with additional annotations, and is the main way that you can manage user access to resources. A project organizes your data science work in one place and also allows you to collaborate with other developers and data scientists in your organization.</p>\n</div>\n<div class=\"paragraph\">\n<p>Within a project, you can add the following functionality:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Data connections so that you can access data without having to hardcode information like endpoints or credentials.</p>\n</li>\n<li>\n<p>Workbenches for working with and processing data, and for developing models.</p>\n</li>\n<li>\n<p>Deployed models so that you can test them and then integrate them into intelligent applications. Deploying a model makes it available as a service that you can access by using an API.</p>\n</li>\n<li>\n<p>Pipelines for automating your ML workflow.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, select <strong>Data Science Projects</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Create data science project</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Create a data science project</strong> dialog, enter a display <strong>Name</strong> for your project.</p>\n</li>\n<li>\n<p>Optional: Edit the <strong>Resource name</strong> for your data science project. The resource name must consist of lowercase alphanumeric characters, '-', and must start and end with an alphanumeric character.</p>\n<div class=\"paragraph\">\n<p><strong>Note:</strong> After you create a project, you can change the project display name but you cannot change the resource name.</p>\n</div>\n</li>\n<li>\n<p>Enter a <strong>description</strong> for your data science project.</p>\n</li>\n<li>\n<p>Click <strong>Create</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>A project details page opens. From this page, you can add data connections, create workbenches, configure pipelines, and deploy models.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"updating-a-data-science-project_nb-server\">Updating a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>You can update your data science project&#8217;s details by changing your project&#8217;s name and description text.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the project whose details you want to update and click <strong>Edit project</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit data science project</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Optional: Update the <strong>name</strong> for your data science project.</p>\n</li>\n<li>\n<p>Optional: Update the <strong>description</strong> for your data science project.</p>\n</li>\n<li>\n<p>Click <strong>Update</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The data science project that you updated is displayed on the <strong>Data Science Projects</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deleting-a-data-science-project_nb-server\">Deleting a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>You can delete data science projects so that they do not appear on the {productname-short} <strong>Data Science Projects</strong> page when you no longer want to use them.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the project that you want to delete and then click <strong>Delete project</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete project</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the project name in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete project</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The data science project that you deleted is no longer displayed on the <strong>Data Science Projects</strong> page.</p>\n</li>\n<li>\n<p>Deleting a data science project deletes any associated workbenches, data science pipelines, cluster storage, and data connections. This data is permanently deleted and is not recoverable.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_project_workbenches\">Using project workbenches</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"creating-a-workbench-select-ide_nb-server\">Creating a workbench and selecting an IDE</h3>\n<div class=\"paragraph _abstract\">\n<p>A workbench is an isolated area where you can examine and work with ML models. You can also work with data and run programs, for example to prepare and clean data. While a workbench is not required if, for example, you only want to service an existing model, one is needed for most data science workflow tasks, such as writing code to process data, or training a model.</p>\n</div>\n<div class=\"paragraph\">\n<p>When you create a workbench, you specify an image (an IDE, packages, and other dependencies). IDEs include JupyterLab and code-server.</p>\n</div>\n<div class=\"paragraph\">\n<p>The IDEs are based on a server-client architecture. Each IDE provides a server that runs in a container on the OpenShift cluster, while the user interface (the client) is displayed in your web browser. For example, the Jupyter notebook server runs in a container on the Red Hat OpenShift cluster. The client is the JupyterLab interface that opens in your web browser on your local computer. All of the commands that you enter in JupyterLab are executed by the notebook server. Similarly, other IDEs like code-server or RStudio Server provide a server that runs in a container on the OpenShift cluster, while the user interface is displayed in your web browser. This architecture allows you to interact through your local computer in a browser environment, while all processing occurs on the cluster. The cluster provides the benefits of larger available resources and security because the data being processed never leaves the cluster.</p>\n</div>\n<div class=\"paragraph\">\n<p>In a workbench, you also configure data connections (to access external data for training models and to save models so that you can deploy them) and cluster storage (for persisting data). Workbenches within the same project can share models and data through object storage with the data science pipelines and model servers.</p>\n</div>\n<div class=\"paragraph\">\n<p>For data science projects that require data retention, you can add container storage to the workbench you are creating.</p>\n</div>\n<div class=\"paragraph\">\n<p>Within a project, you can create multiple workbenches. When to create a new workbench depends on considerations, such as the following:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The workbench configuration (for example, CPU, RAM, or IDE). If you want to avoid editing the configuration of an existing workbenchs configuration to accomodate a new task, you can create a new workbench instead.</p>\n</li>\n<li>\n<p>Separation of tasks or activities. For example, you might want to use one workbench for your Large Language Models (LLM) experimentation activities, another workbench dedicated to a demo, and another workbench for testing.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"about-workbench-images_nb-server\">About workbench images</h4>\n<div class=\"paragraph _abstract\">\n<p>A workbench image (sometimes referred to as a notebook image) is optimized with the tools and libraries that you need for model development. You can use the provided workbench images or an {productname-short} admin user can create custom workbench images adapted to your needs.</p>\n</div>\n<div class=\"paragraph\">\n<p>To provide a consistent, stable platform for your model development, many provided workbench images contain the same version of Python. Most workbench images available on {productname-short} are pre-built and ready for you to use immediately after {productname-short} is installed or upgraded.</p>\n</div>\n<div class=\"paragraph\">\n<p>{productname-long} contains the following notebook images that are available by default.</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<caption class=\"title\">Table 1. Default notebook images</caption>\n<colgroup>\n<col style=\"width: 16.6666%;\">\n<col style=\"width: 83.3334%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Image name</th>\n<th class=\"tableblock halign-left valign-top\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">CUDA</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">If you are working with compute-intensive data science models that require GPU support, use the Compute Unified Device Architecture (CUDA) notebook image to gain access to the NVIDIA CUDA Toolkit. Using this toolkit, you can optimize your work by using GPU-accelerated libraries and optimization tools.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Standard Data Science</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Use the Standard Data Science notebook image for models that do not require TensorFlow or PyTorch. This image contains commonly-used libraries to assist you in developing your machine learning models.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">TensorFlow</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">TensorFlow is an open source platform for machine learning. With TensorFlow, you can build, train and deploy your machine learning models. TensorFlow contains advanced data visualization features, such as computational graph visualizations. It also allows you to easily monitor and track the progress of your models.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">PyTorch</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">PyTorch is an open source machine learning library optimized for deep learning. If you are working with computer vision or natural language processing models, use the Pytorch notebook image.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Minimal Python</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">If you do not require advanced machine learning features, or additional resources for compute-intensive data science work, you can use the Minimal Python image to develop your models.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">TrustyAI</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Use the TrustyAI notebook image to leverage your data science work with model explainability, tracing, and accountability, and runtime monitoring.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">HabanaAI</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">The HabanaAI notebook image optimizes high-performance deep learning (DL) with Habana Gaudi devices. Habana Gaudi devices accelerate DL training workloads and maximize training throughput and efficiency.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">code-server</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"paragraph\">\n<p>With the code-server notebook image, you can customize your notebook environment to meet your needs using a variety of extensions to add new languages, themes, debuggers, and connect to additional services. Enhance the efficiency of your data science work with syntax highlighting, auto-indentation, and bracket matching, as well as an automatic task runner for seamless automation. For more information, see <a href=\"https://github.com/coder/code-server\">code-server in GitHub</a>.<br></p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nElyra-based pipelines are not available with the code-server notebook image.\n</td>\n</tr>\n</table>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">RStudio Server</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"paragraph\">\n<p>Use the RStudio Server notebook image to access the RStudio IDE, an integrated development environment for R, a programming language for statistical computing and graphics.\nFor more information, see <a href=\"https://posit.co/products/open-source/rstudio-server/\">the RStudio Server site</a>.<br></p>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">CUDA - RStudio Server</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"paragraph\">\n<p>Use the CUDA - RStudio Server notebook image to access the RStudio IDE and NVIDIA CUDA Toolkit. RStudio is an integrated development environment for R, a programming language for statistical computing and graphics. With the NVIDIA CUDA toolkit, you can optimize your work using GPU-accelerated libraries and optimization tools.\nFor more information, see <a href=\"https://posit.co/products/open-source/rstudio-server/\">the RStudio Server site</a>.<br></p>\n</div></div></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div class=\"sect3\">\n<h4 id=\"creating-a-project-workbench_nb-server\">Creating a workbench</h4>\n<div class=\"paragraph\">\n<p>When you create a workbench, you specify an image (an IDE, packages, and other dependencies). You can also configure data connections, cluster storage, and add container storage.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you use specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You created a project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n</li>\n<li>\n<p>Click the name of the project that you want to add the workbench to.</p>\n<div class=\"paragraph\">\n<p>A <strong>Details</strong> page for the project opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Workbenches</strong> section, click <strong>Create a workbench</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Create workbench</strong> page, configure the properties of the workbench that you are creating.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Name</strong> field, enter a name for your workbench.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Description</strong> field, enter a description to define your workbench.</p>\n</li>\n<li>\n<p>In the <strong>Notebook image</strong> section, complete the fields to specify the workbench image to use with your workbench.</p>\n<div class=\"paragraph\">\n<p>From the <strong>Image selection</strong> list, select a workbench image that suits your use case. A workbench image includes an IDE and Python packages (reusable code). Optionally, click the <strong>View package information</strong> option to view a list of packages that are included in the image that you selected.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the workbench image has multiple versions available, select the workbench image version to use from the <strong>Versions</strong> section. To use the latest package versions, Red Hat recommends that you use the most recently added image.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nYou can change the workbench image after you create the workbench.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>In the <strong>Deployment size</strong> section, from the <strong>Container size</strong> list, select a container size for your server. The container size controls the number of CPUs, the amount of memory, and the minimum and maximum request capacity of the container.</p>\n</li>\n<li>\n<p>Optional: Select and specify values for any environment variables.</p>\n<div class=\"paragraph\">\n<p>Setting environment variables during the workbench configuration helps you save time later because you do not need to define them in the body of your notebooks, or with the IDE command line interface.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you are using S3-compatible storage, add these recommended environment variables:</p>\n</div>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>AWS_ACCESS_KEY_ID</code> specifies your Access Key ID for Amazon Web Services.</p>\n</li>\n<li>\n<p><code>AWS_SECRET_ACCESS_KEY</code> specifies your Secret access key for the account specified in <code>AWS_ACCESS_KEY_ID</code>.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>{productname-short} stores the credentials as Kubernetes secrets in a protected namespace if you select <strong>Secret</strong> when you add the variable.</p>\n</div>\n</li>\n<li>\n<p>Configure the storage for your workbench. Select one of the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Create new persistent storage</strong> to create storage that is retained after you shut down your workbench. Complete the relevant fields to define the storage.</p>\n</li>\n<li>\n<p><strong>Use existing persistent storage</strong> to reuse existing storage and select the storage from the <strong>Persistent storage</strong> list.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Optionally, you can add a data connection to your workbench. A data connection is a resource that contains the configuration parameters needed to connect to a data source or an object storage bucket. Currently, only S3-Compatible data connections are supported. You can use storage buckets for storing data, models, and pipeline artifacts. You can also use a data connection to specify the location of a model that you want to deploy.</p>\n<div class=\"paragraph\">\n<p>In the <strong>Data connections</strong> section, select the <strong>Use a data connection</strong> checkbox.</p>\n</div>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Create a new data connection as follows:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Select <strong>Create new data connection</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter a unique name for the data connection.</p>\n</li>\n<li>\n<p>In the <strong>Access key</strong> field, enter the access key ID for the S3-compatible object storage provider.</p>\n</li>\n<li>\n<p>In the <strong>Secret key</strong> field, enter the secret access key for the S3-compatible object storage account that you specified.</p>\n</li>\n<li>\n<p>In the <strong>Endpoint</strong> field, enter the endpoint of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Region</strong> field, enter the default region of your S3-compatible object storage account.</p>\n</li>\n<li>\n<p>In the <strong>Bucket</strong> field, enter the name of your S3-compatible object storage bucket.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Use an existing data connection as follows:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Select <strong>Use existing data connection</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Data connection</strong> list, select a data connection that you previously defined.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Create workbench</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The workbench that you created appears on the <strong>Workbenches</strong> tab for the project.</p>\n</li>\n<li>\n<p>Any cluster storage that you associated with the workbench during the creation process appears on the <strong>Cluster storage</strong> tab for the project.</p>\n</li>\n<li>\n<p>The <strong>Status</strong> column on the <strong>Workbenches</strong> tab displays a status of <strong>Starting</strong> when the workbench server is starting, and <strong>Running</strong> when the workbench has successfully started.</p>\n</li>\n<li>\n<p>Optionally, click the <strong>Open</strong> link to open the IDE in a new window.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"starting-a-workbench_nb-server\">Starting a workbench</h3>\n<div class=\"paragraph _abstract\">\n<p>You can manually start a data science project&#8217;s workbench from the <strong>Workbenches</strong> tab on the project details page. By default, workbenches start immediately after you create them.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that contains a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project whose workbench you want to start.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Workbenches</strong> tab.</p>\n</li>\n<li>\n<p>Click the toggle in the <strong>Status</strong> column for the relevant workbench to start a workbench that is not running.</p>\n<div class=\"paragraph\">\n<p>The status of the workbench that you started changes from <strong>Stopped</strong> to <strong>Running</strong>. After the workbench has started, click <strong>Open</strong> to open the workbench&#8217;s notebook.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The workbench that you started appears on the <strong>Workbenches</strong> tab for the project, with the status of <strong>Running</strong>.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"updating-a-project-workbench_nb-server\">Updating a project workbench</h3>\n<div class=\"paragraph _abstract\">\n<p>If your data science work requires you to change your workbench&#8217;s notebook image, container size, or identifying information, you can update the properties of your project&#8217;s workbench. If you require extra power for use with large datasets, you can assign accelerators to your workbench to optimize performance.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you use specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that has a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project whose workbench you want to update.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Workbenches</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the workbench that you want to update and then click <strong>Edit workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit workbench</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Update any of the workbench properties and then click <strong>Update workbench</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The workbench that you updated appears on the <strong>Workbenches</strong> tab for the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deleting-a-workbench-from-a-data-science-project_nb-server\">Deleting a workbench from a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>You can delete workbenches from your data science projects to help you remove Jupyter notebooks that are no longer relevant to your work.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project with a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to delete the workbench from.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Workbenches</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the workbench that you want to delete and then click <strong>Delete workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete workbench</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the name of the workbench in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete workbench</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The workbench that you deleted is no longer displayed in the <strong>Workbenches</strong> tab for the project.</p>\n</li>\n<li>\n<p>The custom resource (CR) associated with the workbench&#8217;s Jupyter notebook is deleted.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_data_connections\">Using data connections</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"adding-a-data-connection-to-your-data-science-project_nb-server\">Adding a data connection to your data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>You can enhance your data science project by adding a connection to a data source. When you want to work with a very large data sets, you can store your data in an S3-compatible object storage bucket, so that you do not fill up your local storage. You also have the option of associating the data connection with an existing workbench that does not already have a connection.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that you can add a data connection to.</p>\n</li>\n<li>\n<p>You have access to S3-compatible object storage.</p>\n</li>\n<li>\n<p>If you intend to add the data connection to an existing workbench, you have saved any data in the workbench to avoid losing work.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to add a data connection to.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Data connections</strong> tab.</p>\n</li>\n<li>\n<p>Click <strong>Add data connection</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Add data connection</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter a <strong>name</strong> for the data connection.</p>\n</li>\n<li>\n<p>In the <strong>Access key</strong> field, enter the access key ID for your S3-compatible object storage provider.</p>\n</li>\n<li>\n<p>In the <strong>Secret key</strong> field, enter the secret access key for the S3-compatible object storage account you specified.</p>\n</li>\n<li>\n<p>In the <strong>Endpoint</strong> field, enter the endpoint of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Region</strong> field, enter the default region of your S3-compatible object storage account.</p>\n</li>\n<li>\n<p>In the <strong>Bucket</strong> field, enter the name of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>Optional: From the <strong>Connected workbench</strong> list, select a workbench to connect.</p>\n</li>\n<li>\n<p>Click <strong>Add data connection</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The data connection that you added appears in the <strong>Data connections</strong> tab for the project.</p>\n</li>\n<li>\n<p>If you selected a workbench, the workbench is visible in the <strong>Connected workbenches</strong> column in the <strong>Data connections</strong> tab for the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deleting-a-data-connection_nb-server\">Deleting a data connection</h3>\n<div class=\"paragraph _abstract\">\n<p>You can delete data connections from your data science projects to help you remove connections that are no longer relevant to your work.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project with a data connection.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to delete the data connection from.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Data connections</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the data connection that you want to delete and then click <strong>Delete data connection</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete data connection</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the name of the data connection in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete data connection</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The data connection that you deleted is no longer displayed in the <strong>Data connections</strong> tab for the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"updating-a-connected-data-source_nb-server\">Updating a connected data source</h3>\n<div class=\"paragraph _abstract\">\n<p>To use an existing data source with a different workbench, you can change the data source that is connected to your project&#8217;s workbench.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project, created a workbench, and you have defined a data connection.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project whose data source you want to change.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Data connections</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the data source that you want to change and then click <strong>Edit data connection</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit data connection</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Connected workbench</strong> section, select an existing workbench from the list.</p>\n</li>\n<li>\n<p>Click <strong>Update data connection</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The updated data connection is displayed in the <strong>Data connections</strong> tab for the project.</p>\n</li>\n<li>\n<p>You can access your S3 data source using environment variables in the connected workbench.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_configuring_cluster_storage\">Configuring cluster storage</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"adding-cluster-storage-to-your-data-science-project_nb-server\">Adding cluster storage to your data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>For data science projects that require data to be retained, you can add cluster storage to the project. Additionally, you can also connect cluster storage to a specific project&#8217;s workbench.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that you can add cluster storage to.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to add the cluster storage to.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Cluster storage</strong> tab.</p>\n</li>\n<li>\n<p>Click <strong>Add cluster storage</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Add storage</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter a <strong>name</strong> for the cluster storage.</p>\n</li>\n<li>\n<p>Enter a <strong>description</strong> for the cluster storage.</p>\n</li>\n<li>\n<p>Under <strong>Persistent storage size</strong>, enter a new size in gibibytes. The minimum size is 1 GiB, and the maximum size is 16384 GiB.</p>\n</li>\n<li>\n<p>Optional: Select a <strong>workbench</strong> from the list to connect the cluster storage to an existing workbench.</p>\n</li>\n<li>\n<p>If you selected a workbench to connect the storage to, enter the storage directory in the <strong>Mount folder</strong> field.</p>\n</li>\n<li>\n<p>Click <strong>Add storage</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The cluster storage that you added appears in the <strong>Cluster storage</strong> tab for the project.</p>\n</li>\n<li>\n<p>A new persistent volume claim (PVC) is created with the storage size that you defined.</p>\n</li>\n<li>\n<p>The persistent volume claim (PVC) is visible as an attached storage in the <strong>Workbenches</strong> tab for the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"updating-cluster-storage_nb-server\">Updating cluster storage</h3>\n<div class=\"paragraph _abstract\">\n<p>If your data science work requires you to change the identifying information of a project&#8217;s cluster storage or the workbench that the storage is connected to, you can update your project&#8217;s cluster storage to change these properties.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that contains cluster storage.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project whose storage you want to update.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Cluster storage</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the storage that you want to update and then click <strong>Edit storage</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit storage</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Update the storage&#8217;s properties.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Update the <strong>name</strong> for the storage, if applicable.</p>\n</li>\n<li>\n<p>Update the <strong>description</strong> for the storage, if applicable.</p>\n</li>\n<li>\n<p>Increase the <strong>Persistent storage size</strong> for the storage, if applicable.</p>\n<div class=\"paragraph\">\n<p>Note that you can only increase the storage size. Updating the storage size restarts the workbench and makes it unavailable for a period of time that is usually proportional to the size change.</p>\n</div>\n</li>\n<li>\n<p>Update the <strong>workbench</strong> that the storage is connected to, if applicable.</p>\n</li>\n<li>\n<p>If you selected a new workbench to connect the storage to, enter the storage directory in the <strong>Mount folder</strong> field.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Update storage</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>If you increased the storage size, the workbench restarts and is unavailable for a period of time that is usually proportional to the size change.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The storage that you updated appears in the <strong>Cluster storage</strong> tab for the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deleting-cluster-storage-from-a-data-science-project_nb-server\">Deleting cluster storage from a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>You can delete cluster storage from your data science projects to help you free up resources and delete unwanted storage space.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project with cluster storage.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to delete the storage from.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Cluster storage</strong> tab.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the storage that you want to delete and then click <strong>Delete storage</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete storage</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the name of the storage in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete storage</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The storage that you deleted is no longer displayed in the <strong>Cluster storage</strong> tab for the project.</p>\n</li>\n<li>\n<p>The persistent volume (PV) and persistent volume claim (PVC) associated with the cluster storage are both permanently deleted. This data is not recoverable.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_configuring_access_to_data_science_projects\">Configuring access to data science projects</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"configuring-access-to-data-science-projects_nb-server\">Configuring access to data science projects</h3>\n<div class=\"paragraph _abstract\">\n<p>To enable you to work collaboratively on your data science projects with other users, you can share access to your project. After creating your project, you can then set the appropriate access permissions from the {productname-short} user interface.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can assign the following access permission levels to your data science projects:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Admin - Users can modify all areas of a project, including its details (project name and description), components, and access permissions.</p>\n</li>\n<li>\n<p>Edit - Users can modify a project&#8217;s components, such as its workbench, but they cannot edit a project&#8217;s access permissions or its details (project name and description).</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"sharing-access-to-a-data-science-project_nb-server\">Sharing access to a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>To enable your organization to work collaboratively, you can share access to your data science project with other users and groups.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>From the list of data science projects, click the name of the data science project that you want to share access to.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Permissions</strong> tab.</p>\n<div class=\"paragraph\">\n<p>The <strong>Permissions</strong> page for the project opens.</p>\n</div>\n</li>\n<li>\n<p>Provide one or more users with access to the project.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Users</strong> section, click <strong>Add user</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter the user name of the user whom you want to provide access to the project.</p>\n</li>\n<li>\n<p>From the <strong>Permissions</strong> list, select one of the following access permission levels:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Admin: Users with this access level can edit project details and manage access to the project.</p>\n</li>\n<li>\n<p>Edit: Users with this access level can view and edit project components, such as its workbenches, data connections, and storage.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>To confirm your entry, click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>).</p>\n</li>\n<li>\n<p>Optional: To add an additional user, click <strong>Add user</strong> and repeat the process.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Provide one or more OpenShift groups with access to the project.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Groups</strong> section, click <strong>Add group</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Name</strong> list, select a group to provide access to the project.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you do not have <code>cluster-admin</code> permissions, the <strong>Name</strong> list is not visible. Instead, an input field is displayed enabling you to configure group permissions.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>From the <strong>Permissions</strong> list, select one of the following access permission levels:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Admin: Groups with this access permission level can edit project details and manage access to the project.</p>\n</li>\n<li>\n<p>Edit: Groups with this access permission level can view and edit project components, such as its workbenches, data connections, and storage.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>To confirm your entry, click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>).</p>\n</li>\n<li>\n<p>Optional: To add an additional group, click <strong>Add group</strong> and repeat the process.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Users to whom you provided access to the project can perform only the actions permitted by their access permission level.</p>\n</li>\n<li>\n<p>The <strong>Users</strong> and <strong>Groups</strong> sections on the <strong>Permissions</strong> tab show the respective users and groups that you provided with access to the project.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"updating-access-to-a-data-science-project_nb-server\">Updating access to a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>To change the level of collaboration on your data science project, you can update the access permissions of users and groups who have access to your project.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n<li>\n<p>You have previously shared access to your project with other users or groups.</p>\n</li>\n<li>\n<p>You have administrator permissions or you are the project owner.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to change the access permissions of.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Permissions</strong> tab.</p>\n<div class=\"paragraph\">\n<p>The <strong>Permissions</strong> page for the project opens.</p>\n</div>\n</li>\n<li>\n<p>Update the user access permissions to the project.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Name</strong> field, update the user name of the user whom you want to provide access to the project.</p>\n</li>\n<li>\n<p>From the <strong>Permissions</strong> list, update the user access permissions by selecting one of the following:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Admin: Users with this access level can edit project details and manage access to the project.</p>\n</li>\n<li>\n<p>Edit: Users with this access level can view and edit project components, such as its workbenches, data connections, and storage.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>To confirm the update to the entry, click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>).</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Update the OpenShift groups access permissions to the project.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>From the <strong>Name</strong> list, update the group that has access to the project by selecting another group from the list.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you do not have <code>cluster-admin</code> permissions, the <strong>Name</strong> list is not visible. Instead, you can configure group permissions in the input field that appears.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>From the <strong>Permissions</strong> list, update the group access permissions by selecting one of the following:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Admin: Groups with this access permission level can edit project details and manage access to the project.</p>\n</li>\n<li>\n<p>Edit: Groups with this access permission level can view and edit project components, such as its workbenches, data connections, and storage.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>To confirm the update to the entry, click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>).</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <strong>Users</strong> and <strong>Groups</strong> sections on the <strong>Permissions</strong> tab show the respective users and groups whose project access permissions you changed.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"removing-access-to-a-data-science-project_nb-server\">Removing access to a data science project</h3>\n<div class=\"paragraph _abstract\">\n<p>If you no longer want to work collaboratively on your data science project, you can restrict access to your project by removing users and groups that you previously provided access to your project.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to {productname-long}.</p>\n</li>\n<li>\n<p>If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n<li>\n<p>You have previously shared access to your project with other users or groups.</p>\n</li>\n<li>\n<p>You have administrator permissions or you are the project owner.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the {productname-short} dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data Science Projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project that you want to change the access permissions of.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the <strong>Permissions</strong> tab.</p>\n<div class=\"paragraph\">\n<p>The <strong>Permissions</strong> page for the project opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the user or group whose access permissions you want to revoke and click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Users whose access you have revoked can no longer perform the actions that were permitted by their access permission level.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>","id":"f58b18fd-4cec-5d2b-a414-35163a6ea37c","document":{"title":"Working on data science projects"}},"markdownRemark":null},"pageContext":{"id":"f58b18fd-4cec-5d2b-a414-35163a6ea37c"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}