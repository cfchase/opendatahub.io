{"componentChunkName":"component---src-templates-docs-page-tsx","path":"/docs/serving-models/","result":{"data":{"allFile":{"edges":[{"node":{"childAsciidoc":{"fields":{"slug":"/docs/README/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/getting-started-with-open-data-hub/"},"sections":[{"parentId":null,"name":"Logging in to Open Data Hub","level":1,"index":0,"id":"logging-in_get-started"},{"parentId":null,"name":"The Open Data Hub user interface","level":1,"index":1,"id":"user-interface_get-started"},{"parentId":"user-interface_get-started","name":"Global navigation","level":2,"index":0,"id":"_global_navigation"},{"parentId":"user-interface_get-started","name":"Side navigation","level":2,"index":1,"id":"_side_navigation"},{"parentId":null,"name":"Notifications in Open Data Hub","level":1,"index":2,"id":"notifications_get-started"},{"parentId":null,"name":"Creating a data science project","level":1,"index":3,"id":"creating-a-data-science-project_get-started"},{"parentId":null,"name":"Creating a project workbench","level":1,"index":4,"id":"creating-a-project-workbench_get-started"},{"parentId":"creating-a-project-workbench_get-started","name":"Launching Jupyter and starting a notebook server","level":2,"index":0,"id":"launching-jupyter-and-starting-a-notebook-server_get-started"},{"parentId":"creating-a-project-workbench_get-started","name":"Options for notebook server environments","level":2,"index":1,"id":"options-for-notebook-server-environments_get-started"},{"parentId":null,"name":"Tutorials for data scientists","level":1,"index":5,"id":"tutorials-for-data-scientists_get-started"},{"parentId":"tutorials-for-data-scientists_get-started","name":"Accessing tutorials","level":2,"index":0,"id":"accessing-tutorials_get-started"},{"parentId":null,"name":"Configuring your IDE","level":1,"index":6,"id":"configuring-your-ide_get-started"},{"parentId":"configuring-your-ide_get-started","name":"Configuring your code-server workbench","level":2,"index":0,"id":"_configuring_your_code_server_workbench"},{"parentId":"_configuring_your_code_server_workbench","name":"Installing extensions with code-server","level":3,"index":0,"id":"_installing_extensions_with_code_server"},{"parentId":"_installing_extensions_with_code_server","name":"Extensions","level":4,"index":0,"id":"_extensions"},{"parentId":null,"name":"Enabling services connected to Open Data Hub","level":1,"index":7,"id":"enabling-services_get-started"},{"parentId":null,"name":"Disabling applications connected to Open Data Hub","level":1,"index":8,"id":"disabling-applications_get-started"},{"parentId":"disabling-applications_get-started","name":"Removing disabled applications from Open Data Hub","level":2,"index":0,"id":"removing-disabled-applications_get-started"},{"parentId":null,"name":"Support requirements and limitations","level":1,"index":9,"id":"support-requirements-and-limitations_requirements"},{"parentId":"support-requirements-and-limitations_requirements","name":"Supported browsers","level":2,"index":0,"id":"supported-browsers_requirements"},{"parentId":"support-requirements-and-limitations_requirements","name":"Supported services","level":2,"index":1,"id":"supported-services_requirements"},{"parentId":"support-requirements-and-limitations_requirements","name":"Supported packages","level":2,"index":2,"id":"supported-packages_requirements"},{"parentId":null,"name":"Common questions","level":1,"index":10,"id":"common-questions_get-started"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/installing-open-data-hub/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_installv2"},{"parentId":null,"name":"Installing Open Data Hub version 1","level":1,"index":1,"id":"installing-odh-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Installing the Open Data Hub Operator version 1","level":2,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Creating a new project for your Open Data Hub instance","level":2,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Adding an Open Data Hub instance","level":2,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Accessing the Open Data Hub dashboard","level":2,"index":3,"id":"accessing-the-odh-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-resources/"},"sections":[{"parentId":null,"name":"Managing cluster resources","level":1,"index":0,"id":"managing-cluster-resources"},{"parentId":"managing-cluster-resources","name":"Configuring the default PVC size for your cluster","level":2,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-resources","name":"Restoring the default PVC size for your cluster","level":2,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-resources","name":"Enabling GPU support in Open Data Hub","level":2,"index":2,"id":"enabling-gpu-support_managing-resources"},{"parentId":"managing-cluster-resources","name":"Allocating additional resources to Open Data Hub users","level":2,"index":3,"id":"allocating-additional-resources-to-data-science-users_managing-resources"},{"parentId":null,"name":"Managing Jupyter notebook servers","level":1,"index":1,"id":"managing-notebook-servers"},{"parentId":"managing-notebook-servers","name":"Accessing the Jupyter administration interface","level":2,"index":0,"id":"accessing-the-jupyter-administration-interface_managing-resources"},{"parentId":"managing-notebook-servers","name":"Starting notebook servers owned by other users","level":2,"index":1,"id":"starting-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Accessing notebook servers owned by other users","level":2,"index":2,"id":"accessing-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Stopping notebook servers owned by other users","level":2,"index":3,"id":"stopping-notebook-servers-owned-by-other-users_managing-resources"},{"parentId":"managing-notebook-servers","name":"Stopping idle notebooks","level":2,"index":4,"id":"stopping-idle-notebooks_managing-resources"},{"parentId":"managing-notebook-servers","name":"Configuring a custom notebook image","level":2,"index":5,"id":"configuring-a-custom-notebook-image_managing-resources"},{"parentId":null,"name":"Backing up storage data","level":1,"index":2,"id":"backing-up-storage-data_managing-resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-users/"},"sections":[{"parentId":null,"name":"Adding users","level":1,"index":0,"id":"adding-users"},{"parentId":"adding-users","name":"Overview of user types and permissions","level":2,"index":0,"id":"overview-of-user-types-and-permissions_managing-users"},{"parentId":"adding-users","name":"Defining Open Data Hub administrator and user groups","level":2,"index":1,"id":"defining-data-science-admin-and-user-groups_managing-users"},{"parentId":"adding-users","name":"Adding users to specialized Open Data Hub user groups","level":2,"index":2,"id":"adding-users-to-specialized-data-science-user-groups_managing-users"},{"parentId":"adding-users","name":"Viewing Open Data Hub users","level":2,"index":3,"id":"viewing-data-science-users_managing-users"},{"parentId":null,"name":"Deleting users and their resources","level":1,"index":1,"id":"deleting-users"},{"parentId":"deleting-users","name":"About deleting users and their resources","level":2,"index":0,"id":"about-deleting-users-and-resources_managing-users"},{"parentId":"deleting-users","name":"Backing up storage data","level":2,"index":1,"id":"backing-up-storage-data_managing-users"},{"parentId":"deleting-users","name":"Stopping notebook servers owned by other users","level":2,"index":2,"id":"stopping-notebook-servers-owned-by-other-users_managing-users"},{"parentId":"deleting-users","name":"Revoking user access to Jupyter","level":2,"index":3,"id":"revoking-user-access-to-jupyter_managing-users"},{"parentId":"deleting-users","name":"Cleaning up after deleting users","level":2,"index":4,"id":"cleaning-up-after-deleting-users_managing-users"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-data-science-models/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service for a data science project","level":1,"index":0,"id":"enabling-trustyai-service_monitor"},{"parentId":"enabling-trustyai-service_monitor","name":"Enabling the TrustyAI Service by using the dashboard","level":2,"index":0,"id":"enabling-trustyai-service-using-dashboard_monitor"},{"parentId":"enabling-trustyai-service_monitor","name":"Enabling the TrustyAI Service by using the CLI","level":2,"index":1,"id":"enabling-trustyai-service-using-cli_monitor"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":1,"id":"authenticating-trustyai-service_monitor"},{"parentId":null,"name":"Sending training data to a model","level":1,"index":2,"id":"sending-training-data-to-a-model_monitor"},{"parentId":null,"name":"Configuring bias metrics for a model","level":1,"index":3,"id":"configuring-bias-metrics-for-a-model_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Duplicating a bias metric","level":2,"index":1,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"configuring-bias-metrics-for-a-model_bias-monitoring","name":"Deleting a bias metric","level":2,"index":2,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Viewing bias metrics for a model","level":1,"index":4,"id":"viewing-bias-metrics_monitor"},{"parentId":null,"name":"Supported bias metrics","level":1,"index":5,"id":"supported-bias-metrics_monitor"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/serving-models/"},"sections":[{"parentId":null,"name":"About model serving","level":1,"index":0,"id":"about-model-serving_about-model-serving"},{"parentId":null,"name":"Serving small and medium-sized models","level":1,"index":1,"id":"serving-small-and-medium-sized-models_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring model servers","level":2,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":3,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":3,"index":2,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":3,"index":3,"id":"deleting-a-model-server_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Working with deployed models","level":2,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":3,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":3,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":3,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":3,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Monitoring deployed models","level":2,"index":2,"id":"_monitoring_deployed_models"},{"parentId":"_monitoring_deployed_models","name":"Viewing performance metrics for all models on a model server","level":3,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_deployed_models","name":"Viewing HTTP request metrics for a deployed model","level":3,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"},{"parentId":null,"name":"Serving large language models","level":1,"index":2,"id":"serving-large-language-models_serving-large-language-models"},{"parentId":"serving-large-language-models_serving-large-language-models","name":"About the single model serving platform","level":2,"index":0,"id":"about-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"serving-large-language-models_serving-large-language-models","name":"Installing KServe","level":2,"index":1,"id":"installing-kserve_serving-large-language-models"},{"parentId":"serving-large-language-models_serving-large-language-models","name":"Deploying models by using the single model serving platform","level":2,"index":2,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Enabling the single model serving platform","level":3,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Adding a custom model-serving runtime for the single model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Deploying models on the single model serving platform","level":3,"index":2,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Accessing the API endpoints for models deployed on the single model serving platform","level":3,"index":3,"id":"accessing-api-endpoints-for-models-deployed-on-single-model-serving-platform_serving-large-language-models"},{"parentId":"serving-large-language-models_serving-large-language-models","name":"Viewing metrics for the single model serving platform","level":2,"index":3,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-language-models"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":3,"id":"monitoring-model-performance_monitoring-model-performance"},{"parentId":"monitoring-model-performance_monitoring-model-performance","name":"Viewing performance metrics for all models on a model server","level":2,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":"monitoring-model-performance_monitoring-model-performance","name":"Viewing HTTP request metrics for a deployed model","level":2,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/upgrading-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview of upgrading Open Data Hub","level":1,"index":0,"id":"overview-of-upgrading-odh_upgrade"},{"parentId":null,"name":"Requirements for upgrading Open Data Hub","level":1,"index":1,"id":"requirements-for-upgrading-odh_upgrade"},{"parentId":null,"name":"Upgrading Open Data Hub version 1 to version 2","level":1,"index":2,"id":"upgrading-odh-v1-to-v2_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Upgrading the Open Data Hub Operator version 1","level":2,"index":0,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_upgradev1"},{"parentId":null,"name":"Upgrading Open Data Hub version 2.0 to version 2.2","level":1,"index":3,"id":"upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Cleaning up resources","level":2,"index":0,"id":"cleaning-up-resources_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Installing Open Data Hub version 2","level":2,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":3,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":3,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":3,"index":2,"id":"accessing-the-odh-dashboard_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Creating and importing notebooks","level":1,"index":0,"id":"creating-and-importing-notebooks_notebooks"},{"parentId":"creating-and-importing-notebooks_notebooks","name":"Creating a new notebook","level":2,"index":0,"id":"creating-a-new-notebook_notebooks"},{"parentId":"creating-a-new-notebook_notebooks","name":"Notebook images for data scientists","level":3,"index":0,"id":"notebook-images-for-data-scientists_notebooks"},{"parentId":"creating-and-importing-notebooks_notebooks","name":"Uploading an existing notebook file from local storage","level":2,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_notebooks"},{"parentId":"creating-and-importing-notebooks_notebooks","name":"Uploading an existing notebook file from a Git repository using JupyterLab","level":2,"index":2,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_notebooks"},{"parentId":"creating-and-importing-notebooks_notebooks","name":"Uploading an existing notebook file from a Git repository using the command line interface","level":2,"index":3,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_notebooks"},{"parentId":null,"name":"Collaborating on notebooks using Git","level":1,"index":1,"id":"collaborating-on-notebooks-using-git_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Uploading an existing notebook file from a Git repository using JupyterLab","level":2,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Uploading an existing notebook file from a Git repository using the command line interface","level":2,"index":1,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Updating your project with changes from a remote Git repository","level":2,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_git-collab"},{"parentId":"collaborating-on-notebooks-using-git_git-collab","name":"Pushing project changes to a Git repository","level":2,"index":3,"id":"pushing-project-changes-to-a-git-repository_git-collab"},{"parentId":null,"name":"Working on data science projects","level":1,"index":2,"id":"working-on-data-science-projects_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using data science projects","level":2,"index":0,"id":"_using_data_science_projects"},{"parentId":"_using_data_science_projects","name":"Creating a data science project","level":3,"index":0,"id":"creating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Updating a data science project","level":3,"index":1,"id":"updating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Deleting a data science project","level":3,"index":2,"id":"deleting-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using project workbenches","level":2,"index":1,"id":"_using_project_workbenches"},{"parentId":"_using_project_workbenches","name":"Creating a project workbench","level":3,"index":0,"id":"creating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Starting a workbench","level":3,"index":1,"id":"starting-a-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Updating a project workbench","level":3,"index":2,"id":"updating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Deleting a workbench from a data science project","level":3,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Using data connections","level":2,"index":2,"id":"_using_data_connections"},{"parentId":"_using_data_connections","name":"Adding a data connection to your data science project","level":3,"index":0,"id":"adding-a-data-connection-to-your-data-science-project_nb-server"},{"parentId":"_using_data_connections","name":"Deleting a data connection","level":3,"index":1,"id":"deleting-a-data-connection_nb-server"},{"parentId":"_using_data_connections","name":"Updating a connected data source","level":3,"index":2,"id":"updating-a-connected-data-source_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Configuring cluster storage","level":2,"index":3,"id":"_configuring_cluster_storage"},{"parentId":"_configuring_cluster_storage","name":"Adding cluster storage to your data science project","level":3,"index":0,"id":"adding-cluster-storage-to-your-data-science-project_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Updating cluster storage","level":3,"index":1,"id":"updating-cluster-storage_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Deleting cluster storage from a data science project","level":3,"index":2,"id":"deleting-cluster-storage-from-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Configuring access to data science projects","level":2,"index":4,"id":"_configuring_access_to_data_science_projects"},{"parentId":"_configuring_access_to_data_science_projects","name":"Configuring access to data science projects","level":3,"index":0,"id":"configuring-access-to-data-science-projects_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Sharing access to a data science project","level":3,"index":1,"id":"sharing-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Updating access to a data science project","level":3,"index":2,"id":"updating-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Removing access to a data science project","level":3,"index":3,"id":"removing-access-to-a-data-science-project_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Viewing Python packages installed on your notebook server","level":2,"index":5,"id":"viewing-python-packages-installed-on-your-notebook-server_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Installing Python packages on your notebook server","level":2,"index":6,"id":"installing-python-packages-on-your-notebook-server_nb-server"},{"parentId":"working-on-data-science-projects_nb-server","name":"Updating notebook server settings by restarting your server","level":2,"index":7,"id":"updating-notebook-server-settings-by-restarting-your-server_nb-server"},{"parentId":null,"name":"Working with data science pipelines","level":1,"index":3,"id":"working-with-data-science-pipelines_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Managing data science pipelines","level":2,"index":0,"id":"_managing_data_science_pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Configuring a pipeline server","level":3,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Defining a pipeline","level":3,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Importing a data science pipeline","level":3,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Downloading a data science pipeline","level":3,"index":3,"id":"downloading-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a data science pipeline","level":3,"index":4,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a pipeline server","level":3,"index":5,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing the details of a pipeline server","level":3,"index":6,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing existing pipelines","level":3,"index":7,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Managing pipeline runs","level":2,"index":1,"id":"_managing_pipeline_runs"},{"parentId":"_managing_pipeline_runs","name":"Overview of pipeline runs","level":3,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run","level":3,"index":1,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Cloning a scheduled pipeline run","level":3,"index":2,"id":"cloning-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Stopping a triggered pipeline run","level":3,"index":3,"id":"stopping-a-triggered-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a scheduled pipeline run","level":3,"index":4,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a triggered pipeline run","level":3,"index":5,"id":"deleting-a-triggered-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing scheduled pipeline runs","level":3,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing triggered pipeline runs","level":3,"index":7,"id":"viewing-triggered-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing the details of a pipeline run","level":3,"index":8,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Working with pipelines in JupyterLab","level":2,"index":2,"id":"_working_with_pipelines_in_jupyterlab"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Overview of pipelines in JupyterLab","level":3,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Accessing the pipeline editor","level":3,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Creating a runtime configuration","level":3,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Updating a runtime configuration","level":3,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Deleting a runtime configuration","level":3,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Duplicating a runtime configuration","level":3,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Running a pipeline in JupyterLab","level":3,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Exporting a pipeline in JupyterLab","level":3,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-data-science-pipelines_ds-pipelines","name":"Additional resources","level":2,"index":3,"id":"_additional_resources"},{"parentId":null,"name":"Working with accelerators","level":1,"index":4,"id":"working-with-accelerators_accelerators"},{"parentId":"working-with-accelerators_accelerators","name":"Overview of accelerators","level":2,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":"working-with-accelerators_accelerators","name":"Working with accelerator profiles","level":2,"index":1,"id":"working-with-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Creating an accelerator profile","level":3,"index":0,"id":"creating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Updating an accelerator profile","level":3,"index":1,"id":"updating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Deleting an accelerator profile","level":3,"index":2,"id":"deleting-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Viewing accelerator profiles","level":3,"index":3,"id":"viewing-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for notebook images","level":3,"index":4,"id":"configuring-a-recommended-accelerator-for-notebook-images_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":3,"index":5,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":"working-with-accelerators_accelerators","name":"Habana Gaudi integration","level":2,"index":2,"id":"habana-gaudi-integration_accelerators"},{"parentId":"habana-gaudi-integration_accelerators","name":"Enabling Habana Gaudi devices","level":3,"index":0,"id":"enabling-habana-gaudi-devices_accelerators"},{"parentId":null,"name":"Working with distributed workloads","level":1,"index":5,"id":"working-with-distributed-workloads_distributed-workloads"},{"parentId":"working-with-distributed-workloads_distributed-workloads","name":"Overview of distributed workloads","level":2,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":"working-with-distributed-workloads_distributed-workloads","name":"Configuring distributed workloads","level":2,"index":1,"id":"configuring-distributed-workloads_distributed-workloads"},{"parentId":"working-with-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from notebooks","level":2,"index":2,"id":"running-distributed-data-science-workloads-from-notebooks_distributed-workloads"},{"parentId":"working-with-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from data science pipelines","level":2,"index":3,"id":"running-distributed-data-science-workloads-from-ds-pipeline_distributed-workloads"},{"parentId":null,"name":"Troubleshooting common problems in Jupyter for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-in-jupyter-for-administrators_distributed-workloads"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_distributed-workloads","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":2,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_distributed-workloads","name":"A user&#8217;s notebook server does not start","level":2,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-administrators_distributed-workloads","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":2,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"},{"parentId":null,"name":"Troubleshooting common problems in Jupyter for users","level":1,"index":7,"id":"troubleshooting-common-problems-in-jupyter-for-users_distributed-workloads"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_distributed-workloads","name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":2,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_distributed-workloads","name":"My notebook server does not start","level":2,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":"troubleshooting-common-problems-in-jupyter-for-users_distributed-workloads","name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":2,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/_artifacts/document-attributes-global/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/adding-users/"},"sections":[{"parentId":null,"name":"Overview of user types and permissions","level":1,"index":0,"id":"overview-of-user-types-and-permissions_{context}"},{"parentId":null,"name":"Defining {productname-short} administrator and user groups","level":1,"index":1,"id":"defining-data-science-admin-and-user-groups_{context}"},{"parentId":null,"name":"Adding users to specialized {productname-short} user groups","level":1,"index":2,"id":"adding-users-to-specialized-data-science-user-groups_{context}"},{"parentId":null,"name":"Viewing {productname-short} users","level":1,"index":3,"id":"viewing-data-science-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-notebooks-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository using JupyterLab","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_git-collab"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository using the command line interface","level":1,"index":1,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_git-collab"},{"parentId":null,"name":"Updating your project with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_git-collab"},{"parentId":null,"name":"Pushing project changes to a Git repository","level":1,"index":3,"id":"pushing-project-changes-to-a-git-repository_git-collab"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-bias-metrics-for-a-model/"},"sections":[{"parentId":null,"name":"Creating a bias metric","level":1,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":2,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":2,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Duplicating a bias metric","level":1,"index":1,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":null,"name":"Deleting a bias metric","level":1,"index":2,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":2,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":2,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-and-importing-notebooks/"},"sections":[{"parentId":null,"name":"Creating a new notebook","level":1,"index":0,"id":"creating-a-new-notebook_notebooks"},{"parentId":"creating-a-new-notebook_notebooks","name":"Notebook images for data scientists","level":2,"index":0,"id":"notebook-images-for-data-scientists_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-from-local-storage_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository using JupyterLab","level":1,"index":2,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_notebooks"},{"parentId":null,"name":"Uploading an existing notebook file from a Git repository using the command line interface","level":1,"index":3,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface_notebooks"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deleting-users/"},"sections":[{"parentId":null,"name":"About deleting users and their resources","level":1,"index":0,"id":"about-deleting-users-and-resources_{context}"},{"parentId":null,"name":"Backing up storage data","level":1,"index":1,"id":"backing-up-storage-data_{context}"},{"parentId":null,"name":"Stopping notebook servers owned by other users","level":1,"index":2,"id":"stopping-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Revoking user access to Jupyter","level":1,"index":3,"id":"revoking-user-access-to-jupyter_{context}"},{"parentId":null,"name":"Cleaning up after deleting users","level":1,"index":4,"id":"cleaning-up-after-deleting-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v1/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 1","level":1,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":null,"name":"Creating a new project for your Open Data Hub instance","level":1,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":null,"name":"Adding an Open Data Hub instance","level":1,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v2/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 2","level":1,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":1,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":2,"id":"accessing-the-odh-dashboard_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-cluster-resources/"},"sections":[{"parentId":null,"name":"Configuring the default PVC size for your cluster","level":1,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Restoring the default PVC size for your cluster","level":1,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Enabling GPU support in {productname-short}","level":1,"index":2,"id":"enabling-gpu-support_{context}"},{"parentId":null,"name":"Allocating additional resources to {productname-short} users","level":1,"index":3,"id":"allocating-additional-resources-to-data-science-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-notebook-servers/"},"sections":[{"parentId":null,"name":"Accessing the Jupyter administration interface","level":1,"index":0,"id":"accessing-the-jupyter-administration-interface_{context}"},{"parentId":null,"name":"Starting notebook servers owned by other users","level":1,"index":1,"id":"starting-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Accessing notebook servers owned by other users","level":1,"index":2,"id":"accessing-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping notebook servers owned by other users","level":1,"index":3,"id":"stopping-notebook-servers-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping idle notebooks","level":1,"index":4,"id":"stopping-idle-notebooks_{context}"},{"parentId":null,"name":"Configuring a custom notebook image","level":1,"index":5,"id":"configuring-a-custom-notebook-image_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-performance/"},"sections":[{"parentId":null,"name":"Viewing performance metrics for all models on a model server","level":1,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":null,"name":"Viewing HTTP request metrics for a deployed model","level":1,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-large-language-models/"},"sections":[{"parentId":null,"name":"About the single model serving platform","level":1,"index":0,"id":"about-the-single-model-serving-platform_serving-large-language-models"},{"parentId":null,"name":"Installing KServe","level":1,"index":1,"id":"installing-kserve_serving-large-language-models"},{"parentId":null,"name":"Deploying models by using the single model serving platform","level":1,"index":2,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Enabling the single model serving platform","level":2,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Adding a custom model-serving runtime for the single model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Deploying models on the single model serving platform","level":2,"index":2,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-language-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-language-models","name":"Accessing the API endpoints for models deployed on the single model serving platform","level":2,"index":3,"id":"accessing-api-endpoints-for-models-deployed-on-single-model-serving-platform_serving-large-language-models"},{"parentId":null,"name":"Viewing metrics for the single model serving platform","level":1,"index":3,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-language-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-small-and-medium-sized-models/"},"sections":[{"parentId":null,"name":"Configuring model servers","level":1,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":2,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":2,"index":2,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":2,"index":3,"id":"deleting-a-model-server_model-serving"},{"parentId":null,"name":"Working with deployed models","level":1,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":2,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":2,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":2,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":2,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":null,"name":"Monitoring deployed models","level":1,"index":2,"id":"_monitoring_deployed_models"},{"parentId":"_monitoring_deployed_models","name":"Viewing performance metrics for all models on a model server","level":2,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_deployed_models","name":"Viewing HTTP request metrics for a deployed model","level":2,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/support-requirements-and-limitations/"},"sections":[{"parentId":null,"name":"Supported browsers","level":1,"index":0,"id":"supported-browsers_requirements"},{"parentId":null,"name":"Supported services","level":1,"index":1,"id":"supported-services_requirements"},{"parentId":null,"name":"Supported packages","level":1,"index":2,"id":"supported-packages_requirements"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v1-to-v2/"},"sections":[{"parentId":null,"name":"Upgrading the Open Data Hub Operator version 1","level":1,"index":0,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":1,"id":"installing-odh-components_upgradev1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":2,"id":"accessing-the-odh-dashboard_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v2/"},"sections":[{"parentId":null,"name":"Cleaning up resources","level":1,"index":0,"id":"cleaning-up-resources_upgradev2"},{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":0,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":1,"id":"installing-odh-components_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Accessing the Open Data Hub dashboard","level":2,"index":2,"id":"accessing-the-odh-dashboard_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Using data science projects","level":1,"index":0,"id":"_using_data_science_projects"},{"parentId":"_using_data_science_projects","name":"Creating a data science project","level":2,"index":0,"id":"creating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Updating a data science project","level":2,"index":1,"id":"updating-a-data-science-project_nb-server"},{"parentId":"_using_data_science_projects","name":"Deleting a data science project","level":2,"index":2,"id":"deleting-a-data-science-project_nb-server"},{"parentId":null,"name":"Using project workbenches","level":1,"index":1,"id":"_using_project_workbenches"},{"parentId":"_using_project_workbenches","name":"Creating a project workbench","level":2,"index":0,"id":"creating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Starting a workbench","level":2,"index":1,"id":"starting-a-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Updating a project workbench","level":2,"index":2,"id":"updating-a-project-workbench_nb-server"},{"parentId":"_using_project_workbenches","name":"Deleting a workbench from a data science project","level":2,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_nb-server"},{"parentId":null,"name":"Using data connections","level":1,"index":2,"id":"_using_data_connections"},{"parentId":"_using_data_connections","name":"Adding a data connection to your data science project","level":2,"index":0,"id":"adding-a-data-connection-to-your-data-science-project_nb-server"},{"parentId":"_using_data_connections","name":"Deleting a data connection","level":2,"index":1,"id":"deleting-a-data-connection_nb-server"},{"parentId":"_using_data_connections","name":"Updating a connected data source","level":2,"index":2,"id":"updating-a-connected-data-source_nb-server"},{"parentId":null,"name":"Configuring cluster storage","level":1,"index":3,"id":"_configuring_cluster_storage"},{"parentId":"_configuring_cluster_storage","name":"Adding cluster storage to your data science project","level":2,"index":0,"id":"adding-cluster-storage-to-your-data-science-project_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Updating cluster storage","level":2,"index":1,"id":"updating-cluster-storage_nb-server"},{"parentId":"_configuring_cluster_storage","name":"Deleting cluster storage from a data science project","level":2,"index":2,"id":"deleting-cluster-storage-from-a-data-science-project_nb-server"},{"parentId":null,"name":"Configuring access to data science projects","level":1,"index":4,"id":"_configuring_access_to_data_science_projects"},{"parentId":"_configuring_access_to_data_science_projects","name":"Configuring access to data science projects","level":2,"index":0,"id":"configuring-access-to-data-science-projects_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Sharing access to a data science project","level":2,"index":1,"id":"sharing-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Updating access to a data science project","level":2,"index":2,"id":"updating-access-to-a-data-science-project_nb-server"},{"parentId":"_configuring_access_to_data_science_projects","name":"Removing access to a data science project","level":2,"index":3,"id":"removing-access-to-a-data-science-project_nb-server"},{"parentId":null,"name":"Viewing Python packages installed on your notebook server","level":1,"index":5,"id":"viewing-python-packages-installed-on-your-notebook-server_nb-server"},{"parentId":null,"name":"Installing Python packages on your notebook server","level":1,"index":6,"id":"installing-python-packages-on-your-notebook-server_nb-server"},{"parentId":null,"name":"Updating notebook server settings by restarting your server","level":1,"index":7,"id":"updating-notebook-server-settings-by-restarting-your-server_nb-server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-accelerators/"},"sections":[{"parentId":null,"name":"Overview of accelerators","level":1,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":null,"name":"Working with accelerator profiles","level":1,"index":1,"id":"working-with-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Creating an accelerator profile","level":2,"index":0,"id":"creating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Updating an accelerator profile","level":2,"index":1,"id":"updating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Deleting an accelerator profile","level":2,"index":2,"id":"deleting-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Viewing accelerator profiles","level":2,"index":3,"id":"viewing-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for notebook images","level":2,"index":4,"id":"configuring-a-recommended-accelerator-for-notebook-images_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":2,"index":5,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":null,"name":"Habana Gaudi integration","level":1,"index":2,"id":"habana-gaudi-integration_accelerators"},{"parentId":"habana-gaudi-integration_accelerators","name":"Enabling Habana Gaudi devices","level":2,"index":0,"id":"enabling-habana-gaudi-devices_accelerators"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of distributed workloads","level":1,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Configuring distributed workloads","level":1,"index":1,"id":"configuring-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Running distributed data science workloads from notebooks","level":1,"index":2,"id":"running-distributed-data-science-workloads-from-notebooks_distributed-workloads"},{"parentId":null,"name":"Running distributed data science workloads from data science pipelines","level":1,"index":3,"id":"running-distributed-data-science-workloads-from-ds-pipeline_distributed-workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Managing data science pipelines","level":1,"index":0,"id":"_managing_data_science_pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Configuring a pipeline server","level":2,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Defining a pipeline","level":2,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Importing a data science pipeline","level":2,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Downloading a data science pipeline","level":2,"index":3,"id":"downloading-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a data science pipeline","level":2,"index":4,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Deleting a pipeline server","level":2,"index":5,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing the details of a pipeline server","level":2,"index":6,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"_managing_data_science_pipelines","name":"Viewing existing pipelines","level":2,"index":7,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":null,"name":"Managing pipeline runs","level":1,"index":1,"id":"_managing_pipeline_runs"},{"parentId":"_managing_pipeline_runs","name":"Overview of pipeline runs","level":2,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Scheduling a pipeline run","level":2,"index":1,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Cloning a scheduled pipeline run","level":2,"index":2,"id":"cloning-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Stopping a triggered pipeline run","level":2,"index":3,"id":"stopping-a-triggered-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a scheduled pipeline run","level":2,"index":4,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Deleting a triggered pipeline run","level":2,"index":5,"id":"deleting-a-triggered-pipeline-run_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing scheduled pipeline runs","level":2,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing triggered pipeline runs","level":2,"index":7,"id":"viewing-triggered-pipeline-runs_ds-pipelines"},{"parentId":"_managing_pipeline_runs","name":"Viewing the details of a pipeline run","level":2,"index":8,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":null,"name":"Working with pipelines in JupyterLab","level":1,"index":2,"id":"_working_with_pipelines_in_jupyterlab"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Overview of pipelines in JupyterLab","level":2,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Accessing the pipeline editor","level":2,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Creating a runtime configuration","level":2,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Updating a runtime configuration","level":2,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Deleting a runtime configuration","level":2,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Duplicating a runtime configuration","level":2,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Running a pipeline in JupyterLab","level":2,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"_working_with_pipelines_in_jupyterlab","name":"Exporting a pipeline in JupyterLab","level":2,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":null,"name":"Additional resources","level":1,"index":3,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-api-endpoints-for-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-jupyter-administration-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-tutorials/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-data-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-users-to-specialized-data-science-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cloning-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/common-questions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-custom-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-notebook-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-access-to-data-science-projects/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-your-ide/"},"sections":[{"parentId":null,"name":"Configuring your code-server workbench","level":1,"index":0,"id":"_configuring_your_code_server_workbench"},{"parentId":"_configuring_your_code_server_workbench","name":"Installing extensions with code-server","level":2,"index":0,"id":"_installing_extensions_with_code_server"},{"parentId":"_installing_extensions_with_code_server","name":"Extensions","level":3,"index":0,"id":"_extensions"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-data-science-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-triggered-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-applications-connected-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-services-connected-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-gpu-support-in-data-science/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-habana-gaudi-devices/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-service/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service by using the dashboard","level":1,"index":0,"id":"enabling-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Enabling the TrustyAI Service by using the CLI","level":1,"index":1,"id":"enabling-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/habana-gaudi-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/launching-jupyter-and-starting-a-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/logging-in-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/notifications-in-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/notebook-images-for-data-scientists/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/options-for-notebook-server-environments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-disabled-applications-from-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/revoking-user-access-to-jupyter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sending-training-data-to-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-a-triggered-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-idle-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/supported-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/supported-browsers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/supported-packages/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/supported-services/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/the-open-data-hub-user-interface/"},"sections":[{"parentId":null,"name":"Global navigation","level":1,"index":0,"id":"_global_navigation"},{"parentId":null,"name":"Side navigation","level":1,"index":1,"id":"_side_navigation"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-jupyter-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s notebook server does not start","level":1,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-jupyter-for-users/"},"sections":[{"parentId":null,"name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":1,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":null,"name":"My notebook server does not start","level":1,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":null,"name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":1,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-connected-data-source/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/tutorials-for-data-scientists/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-notebook-server-settings-by-restarting-your-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-triggered-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-api-endpoints-for-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-jupyter-administration-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-tutorials/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-data-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-users-to-specialized-data-science-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/common-questions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cloning-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-notebook-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-custom-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-access-to-data-science-projects/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-your-ide/"},"sections":[{"parentId":null,"name":"Configuring your code-server workbench","level":1,"index":0,"id":"_configuring_your_code_server_workbench"},{"parentId":"_configuring_your_code_server_workbench","name":"Installing extensions with code-server","level":2,"index":0,"id":"_installing_extensions_with_code_server"},{"parentId":"_installing_extensions_with_code_server","name":"Extensions","level":3,"index":0,"id":"_extensions"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-data-science-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-triggered-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-applications-connected-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-gpu-support-in-data-science/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-habana-gaudi-devices/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-services-connected-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-service/"},"sections":[{"parentId":null,"name":"Enabling the TrustyAI Service by using the dashboard","level":1,"index":0,"id":"enabling-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Enabling the TrustyAI Service by using the CLI","level":1,"index":1,"id":"enabling-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/habana-gaudi-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/launching-jupyter-and-starting-a-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/logging-in-to-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/notebook-images-for-data-scientists/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/notifications-in-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/options-for-notebook-server-environments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-disabled-applications-from-open-data-hub/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/revoking-user-access-to-jupyter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sending-training-data-to-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-a-triggered-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-idle-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/supported-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-notebook-servers-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/supported-browsers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/supported-packages/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/supported-services/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/the-open-data-hub-user-interface/"},"sections":[{"parentId":null,"name":"Global navigation","level":1,"index":0,"id":"_global_navigation"},{"parentId":null,"name":"Side navigation","level":1,"index":1,"id":"_side_navigation"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-jupyter-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s notebook server does not start","level":1,"index":1,"id":"_a_users_notebook_server_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/tutorials-for-data-scientists/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-jupyter-for-users/"},"sections":[{"parentId":null,"name":"I see a <strong>403: Forbidden</strong> error when I log in to Jupyter","level":1,"index":0,"id":"_i_see_a_403_forbidden_error_when_i_log_in_to_jupyter"},{"parentId":null,"name":"My notebook server does not start","level":1,"index":1,"id":"_my_notebook_server_does_not_start"},{"parentId":null,"name":"I see a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when I run my notebook cells","level":1,"index":2,"id":"_i_see_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_i_run_my_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-connected-data-source/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-notebook-server-settings-by-restarting-your-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-the-command-line-interface/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-notebook-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-triggered-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-accelerator-profiles/"},"sections":null}}}]},"asciidoc":{"html":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#about-model-serving_about-model-serving\">About model serving</a></li>\n<li><a href=\"#serving-small-and-medium-sized-models_model-serving\">Serving small and medium-sized models</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#_configuring_model_servers\">Configuring model servers</a></li>\n<li><a href=\"#_working_with_deployed_models\">Working with deployed models</a></li>\n<li><a href=\"#_monitoring_deployed_models\">Monitoring deployed models</a></li>\n</ul>\n</li>\n<li><a href=\"#serving-large-language-models_serving-large-language-models\">Serving large language models</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#about-the-single-model-serving-platform_serving-large-language-models\">About the single model serving platform</a></li>\n<li><a href=\"#installing-kserve_serving-large-language-models\">Installing KServe</a></li>\n<li><a href=\"#deploying-models-using-the-single-model-serving-platform_serving-large-language-models\">Deploying models by using the single model serving platform</a></li>\n<li><a href=\"#viewing-metrics-for-the-single-model-serving-platform_serving-large-language-models\">Viewing metrics for the single model serving platform</a></li>\n</ul>\n</li>\n<li><a href=\"#monitoring-model-performance_monitoring-model-performance\">Monitoring model performance</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#viewing-performance-metrics-for-model-server_monitoring-model-performance\">Viewing performance metrics for all models on a model server</a></li>\n<li><a href=\"#viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance\">Viewing HTTP request metrics for a deployed model</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div class=\"sect1\">\n<h2 id=\"about-model-serving_about-model-serving\">About model serving</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Serving trained models on Open Data Hub means deploying the models on your OpenShift cluster to test and then integrate them into intelligent applications. Deploying a model makes it available as a service that you can access by using an API. This enables you to return predictions based on data inputs that you provide through API calls. This process is known as model <em>inferencing</em>. When you serve a model on Open Data Hub, the inference endpoints that you can access for the deployed model are shown in the dashboard.</p>\n</div>\n<div class=\"paragraph\">\n<p>Open Data Hub provides the following model serving platforms:</p>\n</div>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">Single model serving platform</dt>\n<dd>\n<p>For deploying large language models (LLMs), Open Data Hub includes a <em>single model serving platform</em> that is based on the <a href=\"https://github.com/kserve/kserve\" target=\"_blank\" rel=\"noopener\">KServe</a> component. Because each model is deployed from its own model server, the single model serving platform helps you to deploy, monitor, scale, and maintain LLMs.</p>\n</dd>\n<dt class=\"hdlist1\">Multi-model serving platform</dt>\n<dd>\n<p>For deploying small and medium-sized models (that is, models that are not considered to be large language models), Open Data Hub includes a <em>multi-model serving platform</em> that is based on the <a href=\"https://github.com/kserve/modelmesh\" target=\"_blank\" rel=\"noopener\">ModelMesh</a> component. On the multi-model serving platform, you can deploy multiple models on the same model server. Each of the deployed models shares the server resources. This approach can be advantageous on OpenShift clusters that have finite compute resources or pods.</p>\n</dd>\n</dl>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"serving-small-and-medium-sized-models_model-serving\">Serving small and medium-sized models</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>On the multi-model serving platform, multiple models can be deployed from the same model server and share the server resources.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_configuring_model_servers\">Configuring model servers</h3>\n<div class=\"sect3\">\n<h4 id=\"enabling-the-multi-model-serving-platform_model-serving\">Enabling the multi-model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>To use the multi-model serving platform, you must first enable the platform.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the admin group (for example, <code>odh-admins</code>) in OpenShift.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Settings</strong>  <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Locate the <strong>Model serving platforms</strong> section.</p>\n</li>\n<li>\n<p>Select the <strong>Multi-model serving platform</strong> checkbox.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving\">Adding a custom model-serving runtime for the multi-model serving platform</h4>\n<div class=\"paragraph\">\n<p>A model-serving runtime adds support for a specified set of model frameworks (that is, formats). By default, the multi-model serving platform includes the OpenVINO Model Server runtime. However, if this runtime doesn&#8217;t meet your needs (it doesn&#8217;t support a particular model format, for example), you can add your own, custom runtime.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an administrator, you can use the Open Data Hub dashboard to add and enable a custom model-serving runtime. You can then choose the custom runtime when you create a new model server for the multi-model serving platform.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nOpen Data Hub enables you to add your own custom runtimes, but does not support the runtimes themselves. You are responsible for correctly configuring and maintaining custom runtimes. You are also responsible for ensuring that you are licensed to use any custom runtimes that you add.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist _abstract\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as an administrator.</p>\n</li>\n<li>\n<p>You are familiar with how to <a href=\"https://opendatahub.io/docs/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving\">add a model server to your project</a>. When you have added a custom model-serving runtime, you must configure a new model server to use the runtime.</p>\n</li>\n<li>\n<p>You have reviewed the example runtimes in the <a href=\"https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes\" target=\"_blank\" rel=\"noopener\">kserve/modelmesh-serving</a> repository. You can use these examples as starting points. However, each runtime requires some further modification before you can deploy it in Open Data Hub. The required modifications are described in the following procedure.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nOpen Data Hub includes the OpenVINO Model Server runtime by default. You do not need to add this runtime to Open Data Hub.\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &gt; <strong>Serving runtimes</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Serving runtimes</strong> page opens and shows the model-serving runtimes that are already installed and enabled.</p>\n</div>\n</li>\n<li>\n<p>To add a custom runtime, choose one of the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To start with an existing runtime (for example the OpenVINO Model Server runtime), click the action menu (&#8942;) next to the existing runtime and then click <strong>Duplicate</strong>.</p>\n</li>\n<li>\n<p>To add a new custom runtime, click <strong>Add serving runtime</strong>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>In the <strong>Select the model serving platforms this runtime supports</strong> list, perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To add a custom runtime for only the multi-model serving platform, select <strong>Multi-model serving platform</strong>.</p>\n</li>\n<li>\n<p>To add a custom runtime for both the multi- and single model serving platforms, select <strong>Single-model and multi-model serving platforms</strong>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Optional: If you started a new runtime (rather than duplicating an existing one), add your code by choosing one of the following options:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Upload a YAML file</strong></p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Upload files</strong>.</p>\n</li>\n<li>\n<p>In the file browser, select a YAML file on your computer. This file might be the one of the example runtimes that you downloaded from the <a href=\"https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes\" target=\"_blank\" rel=\"noopener\">kserve/modelmesh-serving</a> repository.</p>\n<div class=\"paragraph\">\n<p>The embedded YAML editor opens and shows the contents of the file that you uploaded.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p><strong>Enter YAML code directly in the editor</strong></p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Start from scratch</strong>.</p>\n</li>\n<li>\n<p>Enter or paste YAML code directly in the embedded editor. The YAML that you paste might be copied from one of the example runtimes in the <a href=\"https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes\" target=\"_blank\" rel=\"noopener\">kserve/modelmesh-serving</a> repository.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n<li>\n<p>Optional: If you are adding one of the example runtimes in the <a href=\"https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes\" target=\"_blank\" rel=\"noopener\">kserve/modelmesh-serving</a> repository, perform the following modifications:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the YAML editor, locate the <code>kind</code> field for your runtime. Update the value of this field to <code>ServingRuntime</code>.</p>\n</li>\n<li>\n<p>In the <a href=\"https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml\" target=\"_blank\" rel=\"noopener\">kustomization.yaml</a> file in the <a href=\"https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes\" target=\"_blank\" rel=\"noopener\">kserve/modelmesh-serving</a> repository, take note of the <code>newName</code> and <code>newTag</code> values for the runtime that you want to add. You will specify these values in a later step.</p>\n</li>\n<li>\n<p>In the YAML editor for your custom runtime, locate the <code>containers.image</code> field.</p>\n</li>\n<li>\n<p>Update the value of the <code>containers.image</code> field in the format <code>newName:newTag</code>, based on the values that you previously noted in the <a href=\"https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml\" target=\"_blank\" rel=\"noopener\">kustomization.yaml</a> file. Some examples are shown.</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">Nvidia Triton Inference Server</dt>\n<dd>\n<div class=\"paragraph\">\n<p><code>image: nvcr.io/nvidia/tritonserver:23.04-py3</code></p>\n</div>\n</dd>\n<dt class=\"hdlist1\">Seldon Python MLServer</dt>\n<dd>\n<div class=\"paragraph\">\n<p><code>image: seldonio/mlserver:1.3.2</code></p>\n</div>\n</dd>\n<dt class=\"hdlist1\">TorchServe</dt>\n<dd>\n<div class=\"paragraph\">\n<p><code>image: pytorch/torchserve:0.7.1-cpu</code></p>\n</div>\n</dd>\n</dl>\n</div>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>metadata.name</code> field, ensure that the value of the runtime you are adding is unique (that is, the value doesn&#8217;t match a runtime that you have already added).</p>\n</li>\n<li>\n<p>Optional: To configure a custom display name for the runtime that you are adding, add a <code>metadata.annotations.openshift.io/display-name</code> field and specify a value, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>apiVersion: serving.kserve.io/v1alpha1\nkind: ServingRuntime\nmetadata:\n  name: mlserver-0.x\n  annotations:\n    openshift.io/display-name: MLServer</code></pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nIf you do not configure a custom display name for your runtime, Open Data Hub shows the value of the <code>metadata.name</code> field.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Add</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Serving runtimes</strong> page opens and shows the updated list of runtimes that are installed. Observe that the runtime you added is automatically enabled.</p>\n</div>\n</li>\n<li>\n<p>Optional: To edit your custom runtime, click the action menu (&#8942;) and select <strong>Edit</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The model-serving runtime that you added is shown in an enabled state on the <strong>Serving runtimes</strong> page.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p>To learn how to configure a model server that uses a custom model-serving runtime that you have added, see <a href=\"https://opendatahub.io/docs/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving\">Adding a model server to your data science project</a>.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"adding-a-model-server-for-the-multi-model-serving-platform_model-serving\">Adding a model server for the multi-model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>When you have enabled the multi-model serving platform, you must configure a model server to deploy models. If you require extra computing power for use with large datasets, you can assign accelerators to your model server.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you use specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have created a data science project that you can add a model server to.</p>\n</li>\n<li>\n<p>You have enabled the multi-model serving platform.</p>\n</li>\n<li>\n<p>If you want to use a custom model-serving runtime for your model server, you have added and enabled the runtime. See <a href=\"https://opendatahub.io/docs/serving-models/#adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving\">Adding a custom model-serving runtime</a>.</p>\n</li>\n<li>\n<p>If you want to use graphics processing units (GPUs) with your model server, you have enabled GPU support. This includes installing the Node Feature Discovery and GPU Operators. For more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Data Science Projects</strong>.</p>\n</li>\n<li>\n<p>Click the name of the project that you want to configure a model server for.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Models and model servers</strong> section, perform one of the following actions:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you see a <strong>Multi-model serving platform</strong> tile, click <strong>Add model server</strong> on the tile.</p>\n</li>\n<li>\n<p>If you do not see any tiles, click the <strong>Add model server</strong> button.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>Add model server</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Model server name</strong> field, enter a unique name for the model server.</p>\n</li>\n<li>\n<p>From the <strong>Serving runtime</strong> list, select a model-serving runtime that is installed and enabled in your Open Data Hub deployment.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you are using a <em>custom</em> model-serving runtime with your model server and want to use GPUs, you must ensure that your custom runtime supports GPUs and is appropriately configured to use them.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>In the <strong>Number of model replicas to deploy</strong> field, specify a value.</p>\n</li>\n<li>\n<p>From the <strong>Model server size</strong> list, select a value.</p>\n</li>\n<li>\n<p>Optional: If you selected <strong>Custom</strong> in the preceding step, configure the following settings in the <strong>Model server size</strong> section to customize your model server:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>CPUs requested</strong> field, specify the number of CPUs to use with your model server. Use the list beside this field to specify the value in cores or millicores.</p>\n</li>\n<li>\n<p>In the <strong>CPU limit</strong> field, specify the maximum number of CPUs to use with your model server. Use the list beside this field to specify the value in cores or millicores.</p>\n</li>\n<li>\n<p>In the <strong>Memory requested</strong> field, specify the requested memory for the model server in gibibytes (Gi).</p>\n</li>\n<li>\n<p>In the <strong>Memory limit</strong> field, specify the maximum memory limit for the model server in gibibytes (Gi).</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: From the <strong>Accelerator</strong> list, select an accelerator.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>If you selected an accelerator in the preceding step, specify the number of accelerators to use.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: In the <strong>Model route</strong> section, select the <strong>Make deployed models available through an external route</strong> checkbox to make your deployed models available to external clients.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Token authorization</strong> section, select the <strong>Require token authentication</strong> checkbox to require token authentication for your model server. To finish configuring token authentication, perform the following actions:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Service account name</strong> field, enter a service account name for which the token will be generated. The generated token is created and displayed in the <strong>Token secret</strong> field when the model server is configured.</p>\n</li>\n<li>\n<p>To add an additional service account, click <strong>Add a service account</strong> and enter another service account name.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Add</strong>.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The model server that you configured appears in the <strong>Models and model servers</strong> section of the project details page.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Optional: To update the model server, click the action menu (<strong>&#8942;</strong>) beside the model server and select <strong>Edit model server</strong>.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"deleting-a-model-server_model-serving\">Deleting a model server</h4>\n<div class=\"paragraph _abstract\">\n<p>When you no longer need a model server to host models, you can remove it from your data science project.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nWhen you remove a model server, you also remove the models that are hosted on that model server. As a result, the models are no longer available to applications.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have created a data science project and an associated model server.</p>\n</li>\n<li>\n<p>You have notified the users of the applications that access the models that the models will no longer be available.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Data Science Projects</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Data science projects</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the name of the project from which you want to delete the model server.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the project whose model server you want to delete in the <strong>Models and model servers</strong> section and then click <strong>Delete model server</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete model server</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the name of the model server in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete model server</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The model server that you deleted is no longer displayed in the <strong>Models and model servers</strong> section on the project details page.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_working_with_deployed_models\">Working with deployed models</h3>\n<div class=\"sect3\">\n<h4 id=\"deploying-a-model-using-the-multi-model-serving-platform_model-serving\">Deploying a model by using the multi-model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>You can deploy trained models on Open Data Hub to enable you to test and implement them into intelligent applications. Deploying a model makes it available as a service that you can access by using an API. This enables you to return predictions based on data inputs.</p>\n</div>\n<div class=\"paragraph\">\n<p>When you have enabled the multi-model serving platform, you can deploy models on the platform.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have enabled the multi-model serving platform.</p>\n</li>\n<li>\n<p>You have created a data science project and added a model server.</p>\n</li>\n<li>\n<p>You have access to S3-compatible object storage.</p>\n</li>\n<li>\n<p>For the model that you want to deploy, you know the associated folder path in your S3-compatible object storage bucket.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Data Science Projects</strong>.</p>\n</li>\n<li>\n<p>Click the name of the project that you want to deploy a model in.</p>\n<div class=\"paragraph\">\n<p>A project details page opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Models and model servers</strong> section, click <strong>Deploy model</strong>.</p>\n</li>\n<li>\n<p>Configure properties for deploying your model as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Model name</strong> field, enter a unique name for the model that you are deploying.</p>\n</li>\n<li>\n<p>From the <strong>Model framework</strong> list, select a framework for your model.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nThe <strong>Model framework</strong> list shows only the frameworks that are supported by the model-serving runtime that you specified when you configured your model server.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>To specify the location of the model you want to deploy from S3-compatible object storage, perform one of the following sets of actions:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>To use an existing data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Select <strong>Existing data connection</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Name</strong> list, select a data connection that you previously defined.</p>\n</li>\n<li>\n<p>In the <strong>Path</strong> field, enter the folder path that contains the model in your specified data source.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p><strong>To use a new data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>To define a new data connection that your model can access, select <strong>New data connection</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter a unique name for the data connection.</p>\n</li>\n<li>\n<p>In the <strong>Access key</strong> field, enter the access key ID for the S3-compatible object storage provider.</p>\n</li>\n<li>\n<p>In the <strong>Secret key</strong> field, enter the secret access key for the S3-compatible object storage account that you specified.</p>\n</li>\n<li>\n<p>In the <strong>Endpoint</strong> field, enter the endpoint of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Region</strong> field, enter the default region of your S3-compatible object storage account.</p>\n</li>\n<li>\n<p>In the <strong>Bucket</strong> field, enter the name of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Path</strong> field, enter the folder path in your S3-compatible object storage that contains your data file.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Deploy</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Confirm that the deployed model is shown in the <strong>Models and model servers</strong> section of your project, and on the <strong>Model Serving</strong> page of the dashboard with a checkmark in the <strong>Status</strong> column.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p>To learn how to monitor your model for bias, see <a href=\"https://opendatahub.io/docs/monitoring-data-science-models\">Monitoring data science models</a>.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"viewing-a-deployed-model_model-serving\">Viewing a deployed model</h4>\n<div class=\"paragraph _abstract\">\n<p>To analyze the results of your work, you can view a list of deployed models on Open Data Hub. You can also view the current statuses of deployed models and their endpoints.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Model Serving</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Deployed models</strong> page opens.</p>\n</div>\n<div class=\"paragraph\">\n<p>For each model, the page shows details such as the model name, the project in which the model is deployed, the serving runtime that the model uses, and the deployment status.</p>\n</div>\n</li>\n<li>\n<p>Optional: For a given model, click the link in the <strong>Inference endpoint</strong> column to see the inference endpoints for the deployed model.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>A list of previously deployed data science models is displayed on the <strong>Deployed models</strong> page.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p>To learn how to monitor your model for bias, see <a href=\"https://opendatahub.io/docs/monitoring-data-science-models\">Monitoring data science models</a>.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"updating-the-deployment-properties-of-a-deployed-model_model-serving\">Updating the deployment properties of a deployed model</h4>\n<div class=\"paragraph _abstract\">\n<p>You can update the deployment properties of a model that has been deployed previously. This allows you to change the model&#8217;s data connection and name.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have deployed a model on Open Data Hub.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Model serving</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Model Serving</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the model whose deployment properties you want to update and click <strong>Edit</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Deploy model</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Update the deployment properties of the model as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Model Name</strong> field, enter a new, unique name for the model.</p>\n</li>\n<li>\n<p>From the <strong>Model framework</strong> list, select a framework for your model.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nThe <strong>Model framework</strong> list shows only the frameworks that are supported by the model-serving runtime that you specified when you configured your model server.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>To update how you have specified the location of your model, perform one of the following sets of actions:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>If you previously specified an existing data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In the <strong>Path</strong> field, update the folder path that contains the model in your specified data source.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p><strong>If you previously specified a new data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In the <strong>Name</strong> field, update a unique name for the data connection.</p>\n</li>\n<li>\n<p>In the <strong>Access key</strong> field, update the access key ID for the S3-compatible object storage provider.</p>\n</li>\n<li>\n<p>In the <strong>Secret key</strong> field, update the secret access key for the S3-compatible object storage account that you specified.</p>\n</li>\n<li>\n<p>In the <strong>Endpoint</strong> field, update the endpoint of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Region</strong> field, update the default region of your S3-compatible object storage account.</p>\n</li>\n<li>\n<p>In the <strong>Bucket</strong> field, update the name of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Path</strong> field, update the folder path in your S3-compatible object storage that contains your data file.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Deploy</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The model whose deployment properties you updated is displayed on the <strong>Model Serving</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"deleting-a-deployed-model_model-serving\">Deleting a deployed model</h4>\n<div class=\"paragraph _abstract\">\n<p>You can delete models you have previously deployed. This enables you to remove deployed models that are no longer required.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have deployed a model.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Model serving</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Deployed models</strong> page opens.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the deployed model that you want to delete and click <strong>Delete</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete deployed model</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Enter the name of the deployed model in the text field to confirm that you intend to delete it.</p>\n</li>\n<li>\n<p>Click <strong>Delete deployed model</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The model that you deleted is no longer displayed on the <strong>Deployed models</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_monitoring_deployed_models\">Monitoring deployed models</h3>\n<div class=\"sect3\">\n<h4 id=\"viewing-performance-metrics-for-model-server_model-serving\">Viewing performance metrics for all models on a model server</h4>\n<div class=\"paragraph _abstract\">\n<p>In Open Data Hub, you can monitor the following metrics for all the models that are deployed on a model server:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>HTTP requests</strong> - The number of HTTP requests that have failed or succeeded for all models on the server.</p>\n<div class=\"paragraph\">\n<p>Note: You can also view the number of HTTP requests that have failed or succeeded for a specific model, as described in <a href=\"#viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance\">Viewing HTTP request metrics for a deployed model</a>.</p>\n</div>\n</li>\n<li>\n<p><strong>Average response time (ms)</strong> - For all models on the server, the average time it takes the model server to respond to requests.</p>\n</li>\n<li>\n<p><strong>CPU utilization (%)</strong> - The percentage of the CPU&#8217;s capacity that is currently being used by all models on the server.</p>\n</li>\n<li>\n<p><strong>Memory utilization (%)</strong> - The percentage of the system&#8217;s memory that is currently being used by all models on the server.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>You can specify a time range and a refresh interval for these metrics to help you determine, for example, when the peak usage hours are and how the models are performing at a specified time.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have installed Open Data Hub.</p>\n</li>\n<li>\n<p>On the OpenShift cluster where Open Data Hub is installed, user workload monitoring is enabled.</p>\n</li>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>There are deployed data science models in your data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard navigation menu, click <strong>Data Science Projects</strong> and then select the project that contains the data science models that you want to monitor.</p>\n</li>\n<li>\n<p>On the <strong>Components</strong> page, scroll down to the <strong>Models and model servers</strong> section.</p>\n</li>\n<li>\n<p>In the row for the model server that you are interested in, click the action menu (&#8942;) and then select <strong>View model server metrics</strong>.</p>\n</li>\n<li>\n<p>Optional: On the metrics page for the model server, set the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Time range</strong> - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.</p>\n</li>\n<li>\n<p><strong>Refresh interval</strong> - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Scroll down to view data graphs for HTTP requests, average response time, CPU utilization, and memory utilization.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>On the metrics page for the model server, the graphs provide performance metric data.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"viewing-http-request-metrics-for-a-deployed-model_model-serving\">Viewing HTTP request metrics for a deployed model</h4>\n<div class=\"paragraph _abstract\">\n<p>You can view a graph that illustrates the HTTP requests that have failed or succeeded for a specific model.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have installed Open Data Hub.</p>\n</li>\n<li>\n<p>On the OpenShift cluster where Open Data Hub is installed, user workload monitoring is enabled.</p>\n</li>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have deployed a model in a data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard navigation menu, select <strong>Model Serving</strong>.</p>\n</li>\n<li>\n<p>On the <strong>Model Serving</strong> page, select the model that you are interested in.</p>\n</li>\n<li>\n<p>Optional: On the <strong>Endpoint performance</strong> tab, set the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Time range</strong> - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.</p>\n</li>\n<li>\n<p><strong>Refresh interval</strong> - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>The <strong>Endpoint performance</strong> tab shows a graph of the HTTP metrics for the model.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"serving-large-language-models_serving-large-language-models\">Serving large language models</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>For deploying large language models (LLMs), Open Data Hub includes a <em>single model serving platform</em> that is based on the KServe component. Because each model is deployed from its own model server, the single model serving platform helps you to deploy, monitor, scale, and maintain LLMs that require increased resources.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"about-the-single-model-serving-platform_serving-large-language-models\">About the single model serving platform</h3>\n<div class=\"paragraph _abstract\">\n<p>The single model serving platform consists of the following components:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://github.com/opendatahub-io/kserve\" target=\"_blank\" rel=\"noopener\">KServe</a>: A Kubernetes custom resource definition (CRD) that orchestrates model serving for all types of models. It includes model-serving runtimes that implement the loading of given types of model servers. KServe handles the lifecycle of the deployment object, storage access, and networking setup.</p>\n</li>\n<li>\n<p><a href=\"https://docs.openshift.com/serverless/1.29/about/about-serverless.html\" target=\"_blank\" rel=\"noopener\">Red&#160;Hat OpenShift Serverless</a>: A cloud-native development model that allows for serverless deployments of models. OpenShift Serverless is based on the open source <a href=\"https://knative.dev/docs/\" target=\"_blank\" rel=\"noopener\">Knative</a> project.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>To install the single model serving platform, you have the following options:</p>\n</div>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">Automated installation</dt>\n<dd>\n<p>If you have not already created a <code>ServiceMeshControlPlane</code> or <code>KNativeServing</code> resource on your OpenShift cluster, you can configure the Open Data Hub Operator to install KServe and its dependencies.</p>\n</dd>\n<dt class=\"hdlist1\">Manual installation</dt>\n<dd>\n<p>If you have already created a <code>ServiceMeshControlPlane</code> or <code>KNativeServing</code> resource on your OpenShift cluster, you <em>cannot</em> configure the Open Data Hub Operator to install KServe and its dependencies. In this situation, you must install KServe manually.</p>\n</dd>\n</dl>\n</div>\n<div class=\"paragraph\">\n<p>When you have installed KServe, you can use the Open Data Hub dashboard to deploy models using either a standalone TGIS runtime or a composite Caikit-TGIS runtime.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://github.com/IBM/text-generation-inference\" target=\"_blank\" rel=\"noopener\">Text Generation Inference Server (TGIS)</a> is based on an early fork of <a href=\"https://github.com/huggingface/text-generation-inference\" target=\"_blank\" rel=\"noopener\">Hugging Face TGI</a>. Red Hat will continue to develop the standalone TGIS runtime to support TGI models. If a model does not work in the current version of Open Data Hub, support might be added in a future version. In the meantime, you can also add your own, custom runtime to support a TGI model. For more information, see <a href=\"https://opendatahub.io/docs/serving-models/#adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-language-models\">Adding a custom model-serving runtime for the single model serving platform</a>.</p>\n</li>\n<li>\n<p>The composite Caikit-TGIS runtime is based on <a href=\"https://github.com/opendatahub-io/caikit\" target=\"_blank\" rel=\"noopener\">Caikit</a> and <a href=\"https://github.com/IBM/text-generation-inference\" target=\"_blank\" rel=\"noopener\">Text Generation Inference Server (TGIS)</a>. To use this runtime, you must convert your models to Caikit format. For an example, see <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/blob/main/demo/kserve/built-tip.md#bootstrap-process\" target=\"_blank\" rel=\"noopener\">Converting Hugging Face Hub models to Caikit format</a> in the <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/tree/main\" target=\"_blank\" rel=\"noopener\">caikit-tgis-serving</a> repository.</p>\n</li>\n</ul>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>You can also configure monitoring for the single model serving platform and use Prometheus to scrape the available metrics.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"installing-kserve_serving-large-language-models\">Installing KServe</h3>\n<div class=\"paragraph _abstract\">\n<p>To learn how to perform both automated and manual installation of KServe, see <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/tree/main/docs#installation\" target=\"_blank\" rel=\"noopener\">Installation</a> in the <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/tree/main/docs#installation\" target=\"_blank\" rel=\"noopener\">caikit-tgis-serving</a> repository.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deploying-models-using-the-single-model-serving-platform_serving-large-language-models\">Deploying models by using the single model serving platform</h3>\n<div class=\"paragraph _abstract\">\n<p>On the single model serving platform, each model is deployed from its own model server. This helps you to deploy, monitor, scale, and maintain LLMs that require increased resources.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you want to use a self-signed certificate to deploy a model from S3-compatible storage, the single model serving platform (which uses KServe) requires additional configuration. For more information, see the Red Hat Knowledgebase solution article <a href=\"https://access.redhat.com/solutions/7053013\" target=\"_blank\" rel=\"noopener\">How to use self-signed certificates with KServe</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>Alternatively, you can disable SSL authentication for KServe. For more information, see the Red Hat Knowledgebase solution article <a href=\"https://access.redhat.com/solutions/7047512\" target=\"_blank\" rel=\"noopener\">How to skip the validation of SSL for KServe</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-the-single-model-serving-platform_serving-large-language-models\">Enabling the single model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>When you have installed KServe, you can use the Open Data Hub dashboard to enable the single model serving platform. You can also use the dashboard to enable model-serving runtimes for the platform.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the admin group (for example, <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have installed KServe.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Enable the single model serving platform as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the left menu, click <strong>Settings</strong> &#8594; <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Locate the <strong>Model serving platforms</strong> section.</p>\n</li>\n<li>\n<p>To enable the single model serving platform for projects, select the <strong>Single model serving platform</strong> checkbox.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Enable pre-installed runtimes for the single-model serving platform as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Serving runtimes</strong>.</p>\n</li>\n<li>\n<p>On the <strong>Serving runtimes</strong> page, set the <strong>Caikit TGIS ServingRuntime for KServe</strong> or <strong>TGIS Standalone ServingRuntime for KServe</strong> runtimes to <strong>Enabled</strong>.</p>\n<div class=\"paragraph\">\n<p>The single model serving platform is now available for model deployments.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-language-models\">Adding a custom model-serving runtime for the single model serving platform</h4>\n<div class=\"paragraph\">\n<p>A model-serving runtime adds support for a specified set of model frameworks (that is, formats). By default, the single model serving platform includes a composite Caikit-TGIS runtime and a standalone TGIS runtime. However, if these runtimes don&#8217;t meet your needs (they don&#8217;t support a particular model format, for example), you can add your own, custom runtimes. For example, you might find that the TGIS runtime does not support a particular model format that is supported by <a href=\"https://huggingface.co/docs/text-generation-inference/supported_models\" target=\"_blank\" rel=\"noopener\">Hugging Face Text Generation Inference (TGI)</a>. In this case, you can create a custom runtime to add support for the model.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an administrator, you can use the Open Data Hub interface to add and enable a custom model-serving runtime. You can then choose the custom runtime when you deploy a model on the single model serving platform.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nOpen Data Hub enables you to add your own custom runtimes, but does not support the runtimes themselves. You are responsible for correctly configuring and maintaining custom runtimes. You are also responsible for ensuring that you are licensed to use any custom runtimes that you add.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist _abstract\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as an administrator.</p>\n</li>\n<li>\n<p>You have built your custom runtime and added the image to a container image repository such as <a href=\"https://quay.io\" target=\"_blank\" rel=\"noopener\">Quay</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &gt; <strong>Serving runtimes</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Serving runtimes</strong> page opens and shows the model-serving runtimes that are already installed and enabled.</p>\n</div>\n</li>\n<li>\n<p>To add a custom runtime, choose one of the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To start with an existing runtime (for example,\n<strong>TGIS Standalone ServingRuntime for KServe</strong>), click the action menu (&#8942;) next to the existing runtime and then click <strong>Duplicate</strong>.</p>\n</li>\n<li>\n<p>To add a new custom runtime, click <strong>Add serving runtime</strong>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>In the <strong>Select the model serving platforms this runtime supports</strong> list, perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To add a runtime for only the single model serving platform, select <strong>Single-model serving platform</strong>.</p>\n</li>\n<li>\n<p>To add a runtime for both the single- and multi-model serving platforms, select <strong>Single-model and multi-model serving platforms</strong>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Optional: If you started a new runtime (rather than duplicating an existing one), add your code by choosing one of the following options:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Upload a YAML file</strong></p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Upload files</strong>.</p>\n</li>\n<li>\n<p>In the file browser, select a YAML file on your computer.</p>\n<div class=\"paragraph\">\n<p>The embedded YAML editor opens and shows the contents of the file that you uploaded.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p><strong>Enter YAML code directly in the editor</strong></p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Start from scratch</strong>.</p>\n</li>\n<li>\n<p>Enter or paste YAML code directly in the embedded editor.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nIn many cases, creating a custom runtime will require adding new or custom parameters to the <code>env</code> section of the <code>ServingRuntime</code> specification.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Add</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Serving runtimes</strong> page opens and shows the updated list of runtimes that are installed. Observe that the runtime you added is automatically enabled.</p>\n</div>\n</li>\n<li>\n<p>Optional: To edit your custom runtime, click the action menu (&#8942;) and select <strong>Edit</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The model-serving runtime that you added is shown in an enabled state on the <strong>Serving runtimes</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"deploying-models-on-the-single-model-serving-platform_serving-large-language-models\">Deploying models on the single model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>When you have enabled the single model serving platform, you can enable the standalone TGIS or composite Caikit-TGIS runtimes and start to deploy models on the platform.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<a href=\"https://github.com/IBM/text-generation-inference\" target=\"_blank\" rel=\"noopener\">Text Generation Inference Server (TGIS)</a> is based on an early fork of <a href=\"https://github.com/huggingface/text-generation-inference\" target=\"_blank\" rel=\"noopener\">Hugging Face TGI</a>. Red Hat will continue to develop the standalone TGIS runtime to support TGI models. If a model does not work in the current version of Open Data Hub, support might be added in a future version. In the meantime, you can also add your own, custom runtime to support a TGI model. For more information, see <a href=\"https://opendatahub.io/docs/serving-models/#adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-language-models\">Adding a custom model-serving runtime for the single model serving platform</a>.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have installed KServe.</p>\n</li>\n<li>\n<p>You have enabled the single model serving platform.</p>\n</li>\n<li>\n<p>You have created a data science project.</p>\n</li>\n<li>\n<p>To use the Caikit-TGIS runtime, you have converted your model to Caikit format. For an example, see <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/blob/main/demo/kserve/built-tip.md#bootstrap-process\" target=\"_blank\" rel=\"noopener\">Converting Hugging Face Hub models to Caikit format</a> in the <a href=\"https://github.com/opendatahub-io/caikit-tgis-serving/tree/main\" target=\"_blank\" rel=\"noopener\">caikit-tgis-serving</a> repository.</p>\n</li>\n<li>\n<p>You know the folder path for the data connection that you want the model to access.</p>\n</li>\n<li>\n<p>If you want to use graphics processing units (GPUs) with your model server, you have enabled GPU support. This includes installing the Node Feature Discovery and GPU Operators. For more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the left menu, click <strong>Data Science Projects</strong>.</p>\n</li>\n<li>\n<p>Click the name of the project that you want to deploy a model in.</p>\n</li>\n<li>\n<p>In the <strong>Models and model servers</strong> section, perform one of the following actions:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you see a <strong>Single model serving platform</strong> tile, click <strong>Deploy model</strong> on the tile.</p>\n</li>\n<li>\n<p>If you do not see any tiles, click the <strong>Deploy model</strong> button.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>Deploy model</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Configure properties for deploying your model as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Model name</strong> field, enter a unique name for the model that you are deploying.</p>\n</li>\n<li>\n<p>In the <strong>Serving runtime</strong> field, select an enabled runtime.</p>\n</li>\n<li>\n<p>From the <strong>Model framework</strong> list, select a value.</p>\n</li>\n<li>\n<p>In the <strong>Number of model replicas to deploy</strong> field, specify a value.</p>\n</li>\n<li>\n<p>From the <strong>Model server size</strong> list, select a value.</p>\n</li>\n<li>\n<p>To specify the location of your model, perform one of the following sets of actions:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>To use an existing data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Select <strong>Existing data connection</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Name</strong> list, select a data connection that you previously defined.</p>\n</li>\n<li>\n<p>In the <strong>Path</strong> field, enter the folder path that contains the model in your specified data source.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p><strong>To use a new data connection</strong></p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>To define a new data connection that your model can access, select <strong>New data connection</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter a unique name for the data connection.</p>\n</li>\n<li>\n<p>In the <strong>Access key</strong> field, enter the access key ID for your S3-compatible object storage provider.</p>\n</li>\n<li>\n<p>In the <strong>Secret key</strong> field, enter the secret access key for the S3-compatible object storage account that you specified.</p>\n</li>\n<li>\n<p>In the <strong>Endpoint</strong> field, enter the endpoint of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Region</strong> field, enter the default region of your S3-compatible object storage account.</p>\n</li>\n<li>\n<p>In the <strong>Bucket</strong> field, enter the name of your S3-compatible object storage bucket.</p>\n</li>\n<li>\n<p>In the <strong>Path</strong> field, enter the folder path in your S3-compatible object storage that contains your data file.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Deploy</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Confirm that the deployed model is shown in the <strong>Models and model servers</strong> section of your project, and on the <strong>Model Serving</strong> page of the dashboard with a check mark in the <strong>Status</strong> column.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"accessing-api-endpoints-for-models-deployed-on-single-model-serving-platform_serving-large-language-models\">Accessing the API endpoints for models deployed on the single model serving platform</h4>\n<div class=\"paragraph _abstract\">\n<p>When you deploy a model by using the single model serving platform, the model is available as a service that you can access using API requests. This enables you to return predictions based on data inputs. To use API requests to interact with your deployed model, you must know how to access the API endpoints that are available.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have deployed a model by using the single model serving platform.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Model Serving</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the project that you deployed a model in.</p>\n</li>\n<li>\n<p>In the <strong>Deployed models</strong> table, for the model that you want to access, copy the URL shown in the <strong>Inference endpoint</strong> column.</p>\n</li>\n<li>\n<p>Depending on what action you want to perform with the model (and if the model supports that action), add one of the following paths to the end of the inference endpoint URL:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p><strong>Caikit TGIS ServingRuntime for KServe</strong></p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>:443/api/v1/task/text-generation</code></p>\n</li>\n<li>\n<p><code>:443/api/v1/task/server-streaming-text-generation</code></p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>TGIS Standalone ServingRuntime for KServe</strong></p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>:443 fmaas.GenerationService/Generate</code></p>\n</li>\n<li>\n<p><code>:443 fmaas.GenerationService/GenerateStream</code></p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nTo query the endpoints for the TGIS standalone runtime, you must also download the files in the <code>proto</code> directory of the IBM <a href=\"https://github.com/IBM/text-generation-inference\" target=\"_blank\" rel=\"noopener\">text-generation-inference</a> repository.\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>As indicated by the paths shown, the single model serving platform uses the HTTPS port of your OpenShift router (usually port 443) to serve external API requests.</p>\n</div>\n</div>\n</div>\n</li>\n<li>\n<p>Use the endpoints to make API requests to your deployed model, as shown in the following example commands:</p>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p><strong>Caikit TGIS ServingRuntime for KServe</strong></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>curl --json '{\"model_id\": \"&lt;model_name&gt;\", \"inputs\": \"At what temperature does water boil?\"}' \\\nhttps://&lt;inference_endpoint_url&gt;:443/api/v1/task/server-streaming-text-generation</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p><strong>TGIS Standalone ServingRuntime for KServe</strong></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>grpcurl -proto text-generation-inference/proto/generation.proto -d \\\n'{\"requests\": [{\"text\":\"At what temperature does water boil?\"}]}' \\\n-H 'mm-model-id: &lt;model_name&gt;' -insecure &lt;inference_url&gt;:443 fmaas.GenerationService/Generate</code></pre>\n</div>\n</div>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-metrics-for-the-single-model-serving-platform_serving-large-language-models\">Viewing metrics for the single model serving platform</h3>\n<div class=\"paragraph _abstract\">\n<p>When a cluster administrator has configured monitoring for the single model serving platform, non-admin users can use the OpenShift web console to view metrics.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Switch to the <strong>Developer</strong> perspective.</p>\n</li>\n<li>\n<p>In the left menu, click <strong>Observe</strong>.</p>\n</li>\n</ol>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"monitoring-model-performance_monitoring-model-performance\">Monitoring model performance</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"viewing-performance-metrics-for-model-server_monitoring-model-performance\">Viewing performance metrics for all models on a model server</h3>\n<div class=\"paragraph _abstract\">\n<p>In Open Data Hub, you can monitor the following metrics for all the models that are deployed on a model server:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>HTTP requests</strong> - The number of HTTP requests that have failed or succeeded for all models on the server.</p>\n<div class=\"paragraph\">\n<p>Note: You can also view the number of HTTP requests that have failed or succeeded for a specific model, as described in <a href=\"#viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance\">Viewing HTTP request metrics for a deployed model</a>.</p>\n</div>\n</li>\n<li>\n<p><strong>Average response time (ms)</strong> - For all models on the server, the average time it takes the model server to respond to requests.</p>\n</li>\n<li>\n<p><strong>CPU utilization (%)</strong> - The percentage of the CPU&#8217;s capacity that is currently being used by all models on the server.</p>\n</li>\n<li>\n<p><strong>Memory utilization (%)</strong> - The percentage of the system&#8217;s memory that is currently being used by all models on the server.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>You can specify a time range and a refresh interval for these metrics to help you determine, for example, when the peak usage hours are and how the models are performing at a specified time.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have installed Open Data Hub.</p>\n</li>\n<li>\n<p>On the OpenShift cluster where Open Data Hub is installed, user workload monitoring is enabled.</p>\n</li>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>There are deployed data science models in your data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard navigation menu, click <strong>Data Science Projects</strong> and then select the project that contains the data science models that you want to monitor.</p>\n</li>\n<li>\n<p>On the <strong>Components</strong> page, scroll down to the <strong>Models and model servers</strong> section.</p>\n</li>\n<li>\n<p>In the row for the model server that you are interested in, click the action menu (&#8942;) and then select <strong>View model server metrics</strong>.</p>\n</li>\n<li>\n<p>Optional: On the metrics page for the model server, set the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Time range</strong> - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.</p>\n</li>\n<li>\n<p><strong>Refresh interval</strong> - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Scroll down to view data graphs for HTTP requests, average response time, CPU utilization, and memory utilization.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>On the metrics page for the model server, the graphs provide performance metric data.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance\">Viewing HTTP request metrics for a deployed model</h3>\n<div class=\"paragraph _abstract\">\n<p>You can view a graph that illustrates the HTTP requests that have failed or succeeded for a specific model.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have installed Open Data Hub.</p>\n</li>\n<li>\n<p>On the OpenShift cluster where Open Data Hub is installed, user workload monitoring is enabled.</p>\n</li>\n<li>\n<p>You have logged in to Open Data Hub.</p>\n</li>\n<li>\n<p>If you are using specialized Open Data Hub groups, you are part of the user group or admin group (for example, <code>odh-users</code> or <code>odh-admins</code>) in OpenShift.</p>\n</li>\n<li>\n<p>You have deployed a model in a data science project.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard navigation menu, select <strong>Model Serving</strong>.</p>\n</li>\n<li>\n<p>On the <strong>Model Serving</strong> page, select the model that you are interested in.</p>\n</li>\n<li>\n<p>Optional: On the <strong>Endpoint performance</strong> tab, set the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Time range</strong> - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.</p>\n</li>\n<li>\n<p><strong>Refresh interval</strong> - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>The <strong>Endpoint performance</strong> tab shows a graph of the HTTP metrics for the model.</p>\n</div>\n</div>\n</div>\n</div>","id":"51c2e86f-2eb0-5cb6-856d-e1fd131f5ce9","document":{"title":"Serving models"}},"markdownRemark":null},"pageContext":{"id":"51c2e86f-2eb0-5cb6-856d-e1fd131f5ce9"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}